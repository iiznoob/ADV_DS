{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h4>Lab No 6</h4>\n",
        "<h4 Align=\"right\">Utkarsh Bhangale<br>**2020802124**</h4>"
      ],
      "metadata": {
        "id": "qCt3l4QaAxYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Text tokenization and lower casing\n",
        "2. Removing special characters\n",
        "3. Contraction expansion\n",
        "4. Removing stopwords\n",
        "5. Stemming\n",
        "6. Lemmatization\n",
        "7. Aggregated Features\n",
        "8. Date-Time Features\n",
        "9. TF-IDF Features\n",
        "10. Word Level TF-IDF\n",
        "11. Character Level TF-IDF\n",
        "12. Word Embedding Features\n",
        "13. Count Features\n",
        "14. Bag-of-n-Grams\n"
      ],
      "metadata": {
        "id": "oGoZ5j7PBFX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPXq7d5DHiYM",
        "outputId": "f1f7c853-88d4-410e-c26a-8ebf2ed7e8df"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0NCeRHvJ6NT",
        "outputId": "a7ab7493-6df3-4bf3-de74-6a9f408365d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.0.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.0.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NucxulP_Bj7A"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Read data\n",
        "with open(\"/content/lab1.docx.txt\", \"r\") as f:\n",
        "    text = f.read()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yk_-dCTiFV0a"
      },
      "outputs": [],
      "source": [
        "data = text.split('\\n')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIRfsLqCGKvB",
        "outputId": "4f6a56c3-2628-4cdf-d7e4-561aeaf5f4fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\\ufeffDiscussions about AI abound.  But critics have begun to recognize that these debates have focused mostly on technical issues.  That is, there are certain problems that need to be addressed and have technical solutions.  Debate rages, accordingly, about how to resolve these issues and move the applications of AI forward.  Perhaps Terry Winograd (1996) was correct when he lamented some time ago that interest in philosophy, what he calls high theory, has dissipated.',\n",
              " '        The application of AI, nonetheless, has pushed the discussion beyond technical devices and their possible uses.  For example, critics have begun to recognize that AI can be quite alienating (Dreyfus 1992; Ritzer 1993).   Workers at Amazon have provided an interesting case study.  While blaming AI, they claim to be overworked and do not stayed employed for long.  They complain regularly about manipulation, stress, job insecurity, and so on.  Clearly, AI is not viewed to be their friend (Livingstone 2018; Vicent 2019).',\n",
              " '        On the other hand, AI can be quite dangerous.  Take driverless cars!  In this application, through the use of AI cars can learn how to navigate streets, other cars, pedestrians, and occasionally unanticipated obstacles.  Any failure can result in a catastrophe, even death.  Questions about the ability of AI to master truly complex activities—those with fluid or shifting frames—have come to the forefront (Goodfellow, Bengio, and Courville 2016).',\n",
              " '        And what about ethical issues?  The focus of developing algorithms, for example, is not necessarily on job loss or intrusions into privacy.  These issues seems to make context difficult to ignore.  Persons tend to become especially nervous when their jobs or privacy are threatened.  Although alienation and learning involve context, the ability to survive and the quality of life seem to go to the heart of the matter.',\n",
              " '        The time appears to be ripe, accordingly, to raise the issue of context in the development of advanced technology.  Shoshana Zuboff (2019) strives to initiate this sort of discussion with her recent foray into the impact of late capitalism on AI.  In this regard, Kate Crawford (2021) strives to move beyond the “nowhere spaces” where she contends most discussion of AI take place.  She believes, for example, that AI is enmeshed in the world’s ecology.  While these entreaties are interesting and relevant, the context provided by Twentieth Century philosophy is missing.  Indeed, the pragmatic framework that is currently the focus of attention of these efforts provides some interesting insights into whether AI can learn or deal with knotty social issues',\n",
              " '        The emphasis of this manuscript, however, is the anti-Cartesian maneuver that characterizes much of contemporary theory.  This change has enormous impact on the potential of AI.  After all, Cartesianism is at the core of digitalization and modern data processing.  Accordingly, the importance of this change in philosophical orientation for understanding the mind, facts, learning, and communication is a vital consideration.  Basic to this reassessment is that the limits of AI become obvious in the absence of Cartesianism.',\n",
              " '        Throughout the Western intellectual tradition, true knowledge has been viewed to be timeless (Grayling 2019).  That is, this information is assumed to be divorced from contexts and other human contingencies.  If immersed in these situations, knowledge can never surpass opinion and only supply anecdotal evidence.  Therefore, most philosophers sought foundations that are universal to establish firm epistemological and moral principles.  Martin Heidegger (1969) refers to this trend as the onto-theological tradition.',\n",
              " '        In many ways, Cartesianism epitomizes this tendency.  In fact, the aim of Cartesians is to advance clear and distinct knowledge, severed from opinion and other sources of human error (Bordo 1987).  In this regard, these thinkers are not necessarily unique, although their strategy is novel.  Rather than speculate about ethereal metaphysical principles, such as Ideas, gods, or cosmic unity, Cartesians make a straightforward proposal known as dualism.']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gC6D6QUNGLxx",
        "outputId": "065a95ab-131c-4209-9d8c-970d81fd42d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\ufeffDiscussions about AI abound.', 'But critics have begun to recognize that these debates have focused mostly on technical issues.', 'That is, there are certain problems that need to be addressed and have technical solutions.', 'Debate rages, accordingly, about how to resolve these issues and move the applications of AI forward.', 'Perhaps Terry Winograd (1996) was correct when he lamented some time ago that interest in philosophy, what he calls high theory, has dissipated.', 'The application of AI, nonetheless, has pushed the discussion beyond technical devices and their possible uses.', 'For example, critics have begun to recognize that AI can be quite alienating (Dreyfus 1992; Ritzer 1993).', 'Workers at Amazon have provided an interesting case study.', 'While blaming AI, they claim to be overworked and do not stayed employed for long.', 'They complain regularly about manipulation, stress, job insecurity, and so on.', 'Clearly, AI is not viewed to be their friend (Livingstone 2018; Vicent 2019).', 'On the other hand, AI can be quite dangerous.', 'Take driverless cars!', 'In this application, through the use of AI cars can learn how to navigate streets, other cars, pedestrians, and occasionally unanticipated obstacles.', 'Any failure can result in a catastrophe, even death.', 'Questions about the ability of AI to master truly complex activities—those with fluid or shifting frames—have come to the forefront (Goodfellow, Bengio, and Courville 2016).', 'And what about ethical issues?', 'The focus of developing algorithms, for example, is not necessarily on job loss or intrusions into privacy.', 'These issues seems to make context difficult to ignore.', 'Persons tend to become especially nervous when their jobs or privacy are threatened.', 'Although alienation and learning involve context, the ability to survive and the quality of life seem to go to the heart of the matter.', 'The time appears to be ripe, accordingly, to raise the issue of context in the development of advanced technology.', 'Shoshana Zuboff (2019) strives to initiate this sort of discussion with her recent foray into the impact of late capitalism on AI.', 'In this regard, Kate Crawford (2021) strives to move beyond the “nowhere spaces” where she contends most discussion of AI take place.', 'She believes, for example, that AI is enmeshed in the world’s ecology.', 'While these entreaties are interesting and relevant, the context provided by Twentieth Century philosophy is missing.', 'Indeed, the pragmatic framework that is currently the focus of attention of these efforts provides some interesting insights into whether AI can learn or deal with knotty social issues\\n        The emphasis of this manuscript, however, is the anti-Cartesian maneuver that characterizes much of contemporary theory.', 'This change has enormous impact on the potential of AI.', 'After all, Cartesianism is at the core of digitalization and modern data processing.', 'Accordingly, the importance of this change in philosophical orientation for understanding the mind, facts, learning, and communication is a vital consideration.', 'Basic to this reassessment is that the limits of AI become obvious in the absence of Cartesianism.', 'Throughout the Western intellectual tradition, true knowledge has been viewed to be timeless (Grayling 2019).', 'That is, this information is assumed to be divorced from contexts and other human contingencies.', 'If immersed in these situations, knowledge can never surpass opinion and only supply anecdotal evidence.', 'Therefore, most philosophers sought foundations that are universal to establish firm epistemological and moral principles.', 'Martin Heidegger (1969) refers to this trend as the onto-theological tradition.', 'In many ways, Cartesianism epitomizes this tendency.', 'In fact, the aim of Cartesians is to advance clear and distinct knowledge, severed from opinion and other sources of human error (Bordo 1987).', 'In this regard, these thinkers are not necessarily unique, although their strategy is novel.', 'Rather than speculate about ethereal metaphysical principles, such as Ideas, gods, or cosmic unity, Cartesians make a straightforward proposal known as dualism.']\n"
          ]
        }
      ],
      "source": [
        "nltk_tokens = nltk.sent_tokenize(text)\n",
        "print(nltk_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Taccb31VG-MD",
        "outputId": "3b696167-633d-4c49-c2b3-6ce07612e4ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\ufeffDiscussions', 'about', 'AI', 'abound', '.', 'But', 'critics', 'have', 'begun', 'to', 'recognize', 'that', 'these', 'debates', 'have', 'focused', 'mostly', 'on', 'technical', 'issues', '.', 'That', 'is', ',', 'there', 'are', 'certain', 'problems', 'that', 'need', 'to', 'be', 'addressed', 'and', 'have', 'technical', 'solutions', '.', 'Debate', 'rages', ',', 'accordingly', ',', 'about', 'how', 'to', 'resolve', 'these', 'issues', 'and', 'move', 'the', 'applications', 'of', 'AI', 'forward', '.', 'Perhaps', 'Terry', 'Winograd', '(', '1996', ')', 'was', 'correct', 'when', 'he', 'lamented', 'some', 'time', 'ago', 'that', 'interest', 'in', 'philosophy', ',', 'what', 'he', 'calls', 'high', 'theory', ',', 'has', 'dissipated', '.', 'The', 'application', 'of', 'AI', ',', 'nonetheless', ',', 'has', 'pushed', 'the', 'discussion', 'beyond', 'technical', 'devices', 'and', 'their', 'possible', 'uses', '.', 'For', 'example', ',', 'critics', 'have', 'begun', 'to', 'recognize', 'that', 'AI', 'can', 'be', 'quite', 'alienating', '(', 'Dreyfus', '1992', ';', 'Ritzer', '1993', ')', '.', 'Workers', 'at', 'Amazon', 'have', 'provided', 'an', 'interesting', 'case', 'study', '.', 'While', 'blaming', 'AI', ',', 'they', 'claim', 'to', 'be', 'overworked', 'and', 'do', 'not', 'stayed', 'employed', 'for', 'long', '.', 'They', 'complain', 'regularly', 'about', 'manipulation', ',', 'stress', ',', 'job', 'insecurity', ',', 'and', 'so', 'on', '.', 'Clearly', ',', 'AI', 'is', 'not', 'viewed', 'to', 'be', 'their', 'friend', '(', 'Livingstone', '2018', ';', 'Vicent', '2019', ')', '.', 'On', 'the', 'other', 'hand', ',', 'AI', 'can', 'be', 'quite', 'dangerous', '.', 'Take', 'driverless', 'cars', '!', 'In', 'this', 'application', ',', 'through', 'the', 'use', 'of', 'AI', 'cars', 'can', 'learn', 'how', 'to', 'navigate', 'streets', ',', 'other', 'cars', ',', 'pedestrians', ',', 'and', 'occasionally', 'unanticipated', 'obstacles', '.', 'Any', 'failure', 'can', 'result', 'in', 'a', 'catastrophe', ',', 'even', 'death', '.', 'Questions', 'about', 'the', 'ability', 'of', 'AI', 'to', 'master', 'truly', 'complex', 'activities—those', 'with', 'fluid', 'or', 'shifting', 'frames—have', 'come', 'to', 'the', 'forefront', '(', 'Goodfellow', ',', 'Bengio', ',', 'and', 'Courville', '2016', ')', '.', 'And', 'what', 'about', 'ethical', 'issues', '?', 'The', 'focus', 'of', 'developing', 'algorithms', ',', 'for', 'example', ',', 'is', 'not', 'necessarily', 'on', 'job', 'loss', 'or', 'intrusions', 'into', 'privacy', '.', 'These', 'issues', 'seems', 'to', 'make', 'context', 'difficult', 'to', 'ignore', '.', 'Persons', 'tend', 'to', 'become', 'especially', 'nervous', 'when', 'their', 'jobs', 'or', 'privacy', 'are', 'threatened', '.', 'Although', 'alienation', 'and', 'learning', 'involve', 'context', ',', 'the', 'ability', 'to', 'survive', 'and', 'the', 'quality', 'of', 'life', 'seem', 'to', 'go', 'to', 'the', 'heart', 'of', 'the', 'matter', '.', 'The', 'time', 'appears', 'to', 'be', 'ripe', ',', 'accordingly', ',', 'to', 'raise', 'the', 'issue', 'of', 'context', 'in', 'the', 'development', 'of', 'advanced', 'technology', '.', 'Shoshana', 'Zuboff', '(', '2019', ')', 'strives', 'to', 'initiate', 'this', 'sort', 'of', 'discussion', 'with', 'her', 'recent', 'foray', 'into', 'the', 'impact', 'of', 'late', 'capitalism', 'on', 'AI', '.', 'In', 'this', 'regard', ',', 'Kate', 'Crawford', '(', '2021', ')', 'strives', 'to', 'move', 'beyond', 'the', '“', 'nowhere', 'spaces', '”', 'where', 'she', 'contends', 'most', 'discussion', 'of', 'AI', 'take', 'place', '.', 'She', 'believes', ',', 'for', 'example', ',', 'that', 'AI', 'is', 'enmeshed', 'in', 'the', 'world', '’', 's', 'ecology', '.', 'While', 'these', 'entreaties', 'are', 'interesting', 'and', 'relevant', ',', 'the', 'context', 'provided', 'by', 'Twentieth', 'Century', 'philosophy', 'is', 'missing', '.', 'Indeed', ',', 'the', 'pragmatic', 'framework', 'that', 'is', 'currently', 'the', 'focus', 'of', 'attention', 'of', 'these', 'efforts', 'provides', 'some', 'interesting', 'insights', 'into', 'whether', 'AI', 'can', 'learn', 'or', 'deal', 'with', 'knotty', 'social', 'issues', 'The', 'emphasis', 'of', 'this', 'manuscript', ',', 'however', ',', 'is', 'the', 'anti-Cartesian', 'maneuver', 'that', 'characterizes', 'much', 'of', 'contemporary', 'theory', '.', 'This', 'change', 'has', 'enormous', 'impact', 'on', 'the', 'potential', 'of', 'AI', '.', 'After', 'all', ',', 'Cartesianism', 'is', 'at', 'the', 'core', 'of', 'digitalization', 'and', 'modern', 'data', 'processing', '.', 'Accordingly', ',', 'the', 'importance', 'of', 'this', 'change', 'in', 'philosophical', 'orientation', 'for', 'understanding', 'the', 'mind', ',', 'facts', ',', 'learning', ',', 'and', 'communication', 'is', 'a', 'vital', 'consideration', '.', 'Basic', 'to', 'this', 'reassessment', 'is', 'that', 'the', 'limits', 'of', 'AI', 'become', 'obvious', 'in', 'the', 'absence', 'of', 'Cartesianism', '.', 'Throughout', 'the', 'Western', 'intellectual', 'tradition', ',', 'true', 'knowledge', 'has', 'been', 'viewed', 'to', 'be', 'timeless', '(', 'Grayling', '2019', ')', '.', 'That', 'is', ',', 'this', 'information', 'is', 'assumed', 'to', 'be', 'divorced', 'from', 'contexts', 'and', 'other', 'human', 'contingencies', '.', 'If', 'immersed', 'in', 'these', 'situations', ',', 'knowledge', 'can', 'never', 'surpass', 'opinion', 'and', 'only', 'supply', 'anecdotal', 'evidence', '.', 'Therefore', ',', 'most', 'philosophers', 'sought', 'foundations', 'that', 'are', 'universal', 'to', 'establish', 'firm', 'epistemological', 'and', 'moral', 'principles', '.', 'Martin', 'Heidegger', '(', '1969', ')', 'refers', 'to', 'this', 'trend', 'as', 'the', 'onto-theological', 'tradition', '.', 'In', 'many', 'ways', ',', 'Cartesianism', 'epitomizes', 'this', 'tendency', '.', 'In', 'fact', ',', 'the', 'aim', 'of', 'Cartesians', 'is', 'to', 'advance', 'clear', 'and', 'distinct', 'knowledge', ',', 'severed', 'from', 'opinion', 'and', 'other', 'sources', 'of', 'human', 'error', '(', 'Bordo', '1987', ')', '.', 'In', 'this', 'regard', ',', 'these', 'thinkers', 'are', 'not', 'necessarily', 'unique', ',', 'although', 'their', 'strategy', 'is', 'novel', '.', 'Rather', 'than', 'speculate', 'about', 'ethereal', 'metaphysical', 'principles', ',', 'such', 'as', 'Ideas', ',', 'gods', ',', 'or', 'cosmic', 'unity', ',', 'Cartesians', 'make', 'a', 'straightforward', 'proposal', 'known', 'as', 'dualism', '.']\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk_tokens_word = nltk.word_tokenize(text)\n",
        "print (nltk_tokens_word)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0clE4a3IhFM",
        "outputId": "de66c60e-2cfd-45b1-c0c1-7386e5b6e9fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\\ufeffdiscussions',\n",
              " 'about',\n",
              " 'ai',\n",
              " 'abound',\n",
              " '.',\n",
              " 'but',\n",
              " 'critics',\n",
              " 'have',\n",
              " 'begun',\n",
              " 'to',\n",
              " 'recognize',\n",
              " 'that',\n",
              " 'these',\n",
              " 'debates',\n",
              " 'have',\n",
              " 'focused',\n",
              " 'mostly',\n",
              " 'on',\n",
              " 'technical',\n",
              " 'issues',\n",
              " '.',\n",
              " 'that',\n",
              " 'is',\n",
              " ',',\n",
              " 'there',\n",
              " 'are',\n",
              " 'certain',\n",
              " 'problems',\n",
              " 'that',\n",
              " 'need',\n",
              " 'to',\n",
              " 'be',\n",
              " 'addressed',\n",
              " 'and',\n",
              " 'have',\n",
              " 'technical',\n",
              " 'solutions',\n",
              " '.',\n",
              " 'debate',\n",
              " 'rages',\n",
              " ',',\n",
              " 'accordingly',\n",
              " ',',\n",
              " 'about',\n",
              " 'how',\n",
              " 'to',\n",
              " 'resolve',\n",
              " 'these',\n",
              " 'issues',\n",
              " 'and',\n",
              " 'move',\n",
              " 'the',\n",
              " 'applications',\n",
              " 'of',\n",
              " 'ai',\n",
              " 'forward',\n",
              " '.',\n",
              " 'perhaps',\n",
              " 'terry',\n",
              " 'winograd',\n",
              " '(',\n",
              " '1996',\n",
              " ')',\n",
              " 'was',\n",
              " 'correct',\n",
              " 'when',\n",
              " 'he',\n",
              " 'lamented',\n",
              " 'some',\n",
              " 'time',\n",
              " 'ago',\n",
              " 'that',\n",
              " 'interest',\n",
              " 'in',\n",
              " 'philosophy',\n",
              " ',',\n",
              " 'what',\n",
              " 'he',\n",
              " 'calls',\n",
              " 'high',\n",
              " 'theory',\n",
              " ',',\n",
              " 'has',\n",
              " 'dissipated',\n",
              " '.',\n",
              " 'the',\n",
              " 'application',\n",
              " 'of',\n",
              " 'ai',\n",
              " ',',\n",
              " 'nonetheless',\n",
              " ',',\n",
              " 'has',\n",
              " 'pushed',\n",
              " 'the',\n",
              " 'discussion',\n",
              " 'beyond',\n",
              " 'technical',\n",
              " 'devices',\n",
              " 'and',\n",
              " 'their',\n",
              " 'possible',\n",
              " 'uses',\n",
              " '.',\n",
              " 'for',\n",
              " 'example',\n",
              " ',',\n",
              " 'critics',\n",
              " 'have',\n",
              " 'begun',\n",
              " 'to',\n",
              " 'recognize',\n",
              " 'that',\n",
              " 'ai',\n",
              " 'can',\n",
              " 'be',\n",
              " 'quite',\n",
              " 'alienating',\n",
              " '(',\n",
              " 'dreyfus',\n",
              " '1992',\n",
              " ';',\n",
              " 'ritzer',\n",
              " '1993',\n",
              " ')',\n",
              " '.',\n",
              " 'workers',\n",
              " 'at',\n",
              " 'amazon',\n",
              " 'have',\n",
              " 'provided',\n",
              " 'an',\n",
              " 'interesting',\n",
              " 'case',\n",
              " 'study',\n",
              " '.',\n",
              " 'while',\n",
              " 'blaming',\n",
              " 'ai',\n",
              " ',',\n",
              " 'they',\n",
              " 'claim',\n",
              " 'to',\n",
              " 'be',\n",
              " 'overworked',\n",
              " 'and',\n",
              " 'do',\n",
              " 'not',\n",
              " 'stayed',\n",
              " 'employed',\n",
              " 'for',\n",
              " 'long',\n",
              " '.',\n",
              " 'they',\n",
              " 'complain',\n",
              " 'regularly',\n",
              " 'about',\n",
              " 'manipulation',\n",
              " ',',\n",
              " 'stress',\n",
              " ',',\n",
              " 'job',\n",
              " 'insecurity',\n",
              " ',',\n",
              " 'and',\n",
              " 'so',\n",
              " 'on',\n",
              " '.',\n",
              " 'clearly',\n",
              " ',',\n",
              " 'ai',\n",
              " 'is',\n",
              " 'not',\n",
              " 'viewed',\n",
              " 'to',\n",
              " 'be',\n",
              " 'their',\n",
              " 'friend',\n",
              " '(',\n",
              " 'livingstone',\n",
              " '2018',\n",
              " ';',\n",
              " 'vicent',\n",
              " '2019',\n",
              " ')',\n",
              " '.',\n",
              " 'on',\n",
              " 'the',\n",
              " 'other',\n",
              " 'hand',\n",
              " ',',\n",
              " 'ai',\n",
              " 'can',\n",
              " 'be',\n",
              " 'quite',\n",
              " 'dangerous',\n",
              " '.',\n",
              " 'take',\n",
              " 'driverless',\n",
              " 'cars',\n",
              " '!',\n",
              " 'in',\n",
              " 'this',\n",
              " 'application',\n",
              " ',',\n",
              " 'through',\n",
              " 'the',\n",
              " 'use',\n",
              " 'of',\n",
              " 'ai',\n",
              " 'cars',\n",
              " 'can',\n",
              " 'learn',\n",
              " 'how',\n",
              " 'to',\n",
              " 'navigate',\n",
              " 'streets',\n",
              " ',',\n",
              " 'other',\n",
              " 'cars',\n",
              " ',',\n",
              " 'pedestrians',\n",
              " ',',\n",
              " 'and',\n",
              " 'occasionally',\n",
              " 'unanticipated',\n",
              " 'obstacles',\n",
              " '.',\n",
              " 'any',\n",
              " 'failure',\n",
              " 'can',\n",
              " 'result',\n",
              " 'in',\n",
              " 'a',\n",
              " 'catastrophe',\n",
              " ',',\n",
              " 'even',\n",
              " 'death',\n",
              " '.',\n",
              " 'questions',\n",
              " 'about',\n",
              " 'the',\n",
              " 'ability',\n",
              " 'of',\n",
              " 'ai',\n",
              " 'to',\n",
              " 'master',\n",
              " 'truly',\n",
              " 'complex',\n",
              " 'activities—those',\n",
              " 'with',\n",
              " 'fluid',\n",
              " 'or',\n",
              " 'shifting',\n",
              " 'frames—have',\n",
              " 'come',\n",
              " 'to',\n",
              " 'the',\n",
              " 'forefront',\n",
              " '(',\n",
              " 'goodfellow',\n",
              " ',',\n",
              " 'bengio',\n",
              " ',',\n",
              " 'and',\n",
              " 'courville',\n",
              " '2016',\n",
              " ')',\n",
              " '.',\n",
              " 'and',\n",
              " 'what',\n",
              " 'about',\n",
              " 'ethical',\n",
              " 'issues',\n",
              " '?',\n",
              " 'the',\n",
              " 'focus',\n",
              " 'of',\n",
              " 'developing',\n",
              " 'algorithms',\n",
              " ',',\n",
              " 'for',\n",
              " 'example',\n",
              " ',',\n",
              " 'is',\n",
              " 'not',\n",
              " 'necessarily',\n",
              " 'on',\n",
              " 'job',\n",
              " 'loss',\n",
              " 'or',\n",
              " 'intrusions',\n",
              " 'into',\n",
              " 'privacy',\n",
              " '.',\n",
              " 'these',\n",
              " 'issues',\n",
              " 'seems',\n",
              " 'to',\n",
              " 'make',\n",
              " 'context',\n",
              " 'difficult',\n",
              " 'to',\n",
              " 'ignore',\n",
              " '.',\n",
              " 'persons',\n",
              " 'tend',\n",
              " 'to',\n",
              " 'become',\n",
              " 'especially',\n",
              " 'nervous',\n",
              " 'when',\n",
              " 'their',\n",
              " 'jobs',\n",
              " 'or',\n",
              " 'privacy',\n",
              " 'are',\n",
              " 'threatened',\n",
              " '.',\n",
              " 'although',\n",
              " 'alienation',\n",
              " 'and',\n",
              " 'learning',\n",
              " 'involve',\n",
              " 'context',\n",
              " ',',\n",
              " 'the',\n",
              " 'ability',\n",
              " 'to',\n",
              " 'survive',\n",
              " 'and',\n",
              " 'the',\n",
              " 'quality',\n",
              " 'of',\n",
              " 'life',\n",
              " 'seem',\n",
              " 'to',\n",
              " 'go',\n",
              " 'to',\n",
              " 'the',\n",
              " 'heart',\n",
              " 'of',\n",
              " 'the',\n",
              " 'matter',\n",
              " '.',\n",
              " 'the',\n",
              " 'time',\n",
              " 'appears',\n",
              " 'to',\n",
              " 'be',\n",
              " 'ripe',\n",
              " ',',\n",
              " 'accordingly',\n",
              " ',',\n",
              " 'to',\n",
              " 'raise',\n",
              " 'the',\n",
              " 'issue',\n",
              " 'of',\n",
              " 'context',\n",
              " 'in',\n",
              " 'the',\n",
              " 'development',\n",
              " 'of',\n",
              " 'advanced',\n",
              " 'technology',\n",
              " '.',\n",
              " 'shoshana',\n",
              " 'zuboff',\n",
              " '(',\n",
              " '2019',\n",
              " ')',\n",
              " 'strives',\n",
              " 'to',\n",
              " 'initiate',\n",
              " 'this',\n",
              " 'sort',\n",
              " 'of',\n",
              " 'discussion',\n",
              " 'with',\n",
              " 'her',\n",
              " 'recent',\n",
              " 'foray',\n",
              " 'into',\n",
              " 'the',\n",
              " 'impact',\n",
              " 'of',\n",
              " 'late',\n",
              " 'capitalism',\n",
              " 'on',\n",
              " 'ai',\n",
              " '.',\n",
              " 'in',\n",
              " 'this',\n",
              " 'regard',\n",
              " ',',\n",
              " 'kate',\n",
              " 'crawford',\n",
              " '(',\n",
              " '2021',\n",
              " ')',\n",
              " 'strives',\n",
              " 'to',\n",
              " 'move',\n",
              " 'beyond',\n",
              " 'the',\n",
              " '“',\n",
              " 'nowhere',\n",
              " 'spaces',\n",
              " '”',\n",
              " 'where',\n",
              " 'she',\n",
              " 'contends',\n",
              " 'most',\n",
              " 'discussion',\n",
              " 'of',\n",
              " 'ai',\n",
              " 'take',\n",
              " 'place',\n",
              " '.',\n",
              " 'she',\n",
              " 'believes',\n",
              " ',',\n",
              " 'for',\n",
              " 'example',\n",
              " ',',\n",
              " 'that',\n",
              " 'ai',\n",
              " 'is',\n",
              " 'enmeshed',\n",
              " 'in',\n",
              " 'the',\n",
              " 'world',\n",
              " '’',\n",
              " 's',\n",
              " 'ecology',\n",
              " '.',\n",
              " 'while',\n",
              " 'these',\n",
              " 'entreaties',\n",
              " 'are',\n",
              " 'interesting',\n",
              " 'and',\n",
              " 'relevant',\n",
              " ',',\n",
              " 'the',\n",
              " 'context',\n",
              " 'provided',\n",
              " 'by',\n",
              " 'twentieth',\n",
              " 'century',\n",
              " 'philosophy',\n",
              " 'is',\n",
              " 'missing',\n",
              " '.',\n",
              " 'indeed',\n",
              " ',',\n",
              " 'the',\n",
              " 'pragmatic',\n",
              " 'framework',\n",
              " 'that',\n",
              " 'is',\n",
              " 'currently',\n",
              " 'the',\n",
              " 'focus',\n",
              " 'of',\n",
              " 'attention',\n",
              " 'of',\n",
              " 'these',\n",
              " 'efforts',\n",
              " 'provides',\n",
              " 'some',\n",
              " 'interesting',\n",
              " 'insights',\n",
              " 'into',\n",
              " 'whether',\n",
              " 'ai',\n",
              " 'can',\n",
              " 'learn',\n",
              " 'or',\n",
              " 'deal',\n",
              " 'with',\n",
              " 'knotty',\n",
              " 'social',\n",
              " 'issues',\n",
              " 'the',\n",
              " 'emphasis',\n",
              " 'of',\n",
              " 'this',\n",
              " 'manuscript',\n",
              " ',',\n",
              " 'however',\n",
              " ',',\n",
              " 'is',\n",
              " 'the',\n",
              " 'anti-cartesian',\n",
              " 'maneuver',\n",
              " 'that',\n",
              " 'characterizes',\n",
              " 'much',\n",
              " 'of',\n",
              " 'contemporary',\n",
              " 'theory',\n",
              " '.',\n",
              " 'this',\n",
              " 'change',\n",
              " 'has',\n",
              " 'enormous',\n",
              " 'impact',\n",
              " 'on',\n",
              " 'the',\n",
              " 'potential',\n",
              " 'of',\n",
              " 'ai',\n",
              " '.',\n",
              " 'after',\n",
              " 'all',\n",
              " ',',\n",
              " 'cartesianism',\n",
              " 'is',\n",
              " 'at',\n",
              " 'the',\n",
              " 'core',\n",
              " 'of',\n",
              " 'digitalization',\n",
              " 'and',\n",
              " 'modern',\n",
              " 'data',\n",
              " 'processing',\n",
              " '.',\n",
              " 'accordingly',\n",
              " ',',\n",
              " 'the',\n",
              " 'importance',\n",
              " 'of',\n",
              " 'this',\n",
              " 'change',\n",
              " 'in',\n",
              " 'philosophical',\n",
              " 'orientation',\n",
              " 'for',\n",
              " 'understanding',\n",
              " 'the',\n",
              " 'mind',\n",
              " ',',\n",
              " 'facts',\n",
              " ',',\n",
              " 'learning',\n",
              " ',',\n",
              " 'and',\n",
              " 'communication',\n",
              " 'is',\n",
              " 'a',\n",
              " 'vital',\n",
              " 'consideration',\n",
              " '.',\n",
              " 'basic',\n",
              " 'to',\n",
              " 'this',\n",
              " 'reassessment',\n",
              " 'is',\n",
              " 'that',\n",
              " 'the',\n",
              " 'limits',\n",
              " 'of',\n",
              " 'ai',\n",
              " 'become',\n",
              " 'obvious',\n",
              " 'in',\n",
              " 'the',\n",
              " 'absence',\n",
              " 'of',\n",
              " 'cartesianism',\n",
              " '.',\n",
              " 'throughout',\n",
              " 'the',\n",
              " 'western',\n",
              " 'intellectual',\n",
              " 'tradition',\n",
              " ',',\n",
              " 'true',\n",
              " 'knowledge',\n",
              " 'has',\n",
              " 'been',\n",
              " 'viewed',\n",
              " 'to',\n",
              " 'be',\n",
              " 'timeless',\n",
              " '(',\n",
              " 'grayling',\n",
              " '2019',\n",
              " ')',\n",
              " '.',\n",
              " 'that',\n",
              " 'is',\n",
              " ',',\n",
              " 'this',\n",
              " 'information',\n",
              " 'is',\n",
              " 'assumed',\n",
              " 'to',\n",
              " 'be',\n",
              " 'divorced',\n",
              " 'from',\n",
              " 'contexts',\n",
              " 'and',\n",
              " 'other',\n",
              " 'human',\n",
              " 'contingencies',\n",
              " '.',\n",
              " 'if',\n",
              " 'immersed',\n",
              " 'in',\n",
              " 'these',\n",
              " 'situations',\n",
              " ',',\n",
              " 'knowledge',\n",
              " 'can',\n",
              " 'never',\n",
              " 'surpass',\n",
              " 'opinion',\n",
              " 'and',\n",
              " 'only',\n",
              " 'supply',\n",
              " 'anecdotal',\n",
              " 'evidence',\n",
              " '.',\n",
              " 'therefore',\n",
              " ',',\n",
              " 'most',\n",
              " 'philosophers',\n",
              " 'sought',\n",
              " 'foundations',\n",
              " 'that',\n",
              " 'are',\n",
              " 'universal',\n",
              " 'to',\n",
              " 'establish',\n",
              " 'firm',\n",
              " 'epistemological',\n",
              " 'and',\n",
              " 'moral',\n",
              " 'principles',\n",
              " '.',\n",
              " 'martin',\n",
              " 'heidegger',\n",
              " '(',\n",
              " '1969',\n",
              " ')',\n",
              " 'refers',\n",
              " 'to',\n",
              " 'this',\n",
              " 'trend',\n",
              " 'as',\n",
              " 'the',\n",
              " 'onto-theological',\n",
              " 'tradition',\n",
              " '.',\n",
              " 'in',\n",
              " 'many',\n",
              " 'ways',\n",
              " ',',\n",
              " 'cartesianism',\n",
              " 'epitomizes',\n",
              " 'this',\n",
              " 'tendency',\n",
              " '.',\n",
              " 'in',\n",
              " 'fact',\n",
              " ',',\n",
              " 'the',\n",
              " 'aim',\n",
              " 'of',\n",
              " 'cartesians',\n",
              " 'is',\n",
              " 'to',\n",
              " 'advance',\n",
              " 'clear',\n",
              " 'and',\n",
              " 'distinct',\n",
              " 'knowledge',\n",
              " ',',\n",
              " 'severed',\n",
              " 'from',\n",
              " 'opinion',\n",
              " 'and',\n",
              " 'other',\n",
              " 'sources',\n",
              " 'of',\n",
              " 'human',\n",
              " 'error',\n",
              " '(',\n",
              " 'bordo',\n",
              " '1987',\n",
              " ')',\n",
              " '.',\n",
              " 'in',\n",
              " 'this',\n",
              " 'regard',\n",
              " ',',\n",
              " 'these',\n",
              " 'thinkers',\n",
              " 'are',\n",
              " 'not',\n",
              " 'necessarily',\n",
              " 'unique',\n",
              " ',',\n",
              " 'although',\n",
              " 'their',\n",
              " 'strategy',\n",
              " 'is',\n",
              " 'novel',\n",
              " '.',\n",
              " 'rather',\n",
              " 'than',\n",
              " 'speculate',\n",
              " 'about',\n",
              " 'ethereal',\n",
              " 'metaphysical',\n",
              " 'principles',\n",
              " ',',\n",
              " 'such',\n",
              " 'as',\n",
              " 'ideas',\n",
              " ',',\n",
              " 'gods',\n",
              " ',',\n",
              " 'or',\n",
              " 'cosmic',\n",
              " 'unity',\n",
              " ',',\n",
              " 'cartesians',\n",
              " 'make',\n",
              " 'a',\n",
              " 'straightforward',\n",
              " 'proposal',\n",
              " 'known',\n",
              " 'as',\n",
              " 'dualism',\n",
              " '.']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "for i in range(len(nltk_tokens_word)):\n",
        "    nltk_tokens_word[i] = nltk_tokens_word[i].lower()\n",
        "    nltk_tokens_word[i] = nltk_tokens_word[i].replace(r\"\\W\",'')\n",
        "    nltk_tokens_word[i] = nltk_tokens_word[i].expandtabs()\n",
        "nltk_tokens_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrSFhwbCIktL",
        "outputId": "f113cf92-e6e6-4df6-d8de-eb445a267cef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Expanded_text: ﻿Discussions about AI abound. But critics have begun to recognize that these debates have focused mostly on technical issues. That is, there are certain problems that need to be addressed and have technical solutions. Debate rages, accordingly, about how to resolve these issues and move the applications of AI forward. Perhaps Terry Winograd (1996) was correct when he lamented some time ago that interest in philosophy, what he calls high theory, has dissipated. The application of AI, nonetheless, has pushed the discussion beyond technical devices and their possible uses. For example, critics have begun to recognize that AI can be quite alienating (Dreyfus 1992; Ritzer 1993). Workers at Amazon have provided an interesting case study. While blaming AI, they claim to be overworked and do not stayed employed for long. They complain regularly about manipulation, stress, job insecurity, and so on. Clearly, AI is not viewed to be their friend (Livingstone 2018; Vicent 2019). On the other hand, AI can be quite dangerous. Take driverless cars! In this application, through the use of AI cars can learn how to navigate streets, other cars, pedestrians, and occasionally unanticipated obstacles. Any failure can result in a catastrophe, even death. Questions about the ability of AI to master truly complex activities—those with fluid or shifting frames—have come to the forefront (Goodfellow, Bengio, and Courville 2016). And what about ethical issues? The focus of developing algorithms, for example, is not necessarily on job loss or intrusions into privacy. These issues seems to make context difficult to ignore. Persons tend to become especially nervous when their jobs or privacy are threatened. Although alienation and learning involve context, the ability to survive and the quality of life seem to go to the heart of the matter. The time appears to be ripe, accordingly, to raise the issue of context in the development of advanced technology. Shoshana Zuboff (2019) strives to initiate this sort of discussion with her recent foray into the impact of late capitalism on AI. In this regard, Kate Crawford (2021) strives to move beyond the “nowhere spaces” where she contends most discussion of AI take place. She believes, for example, that AI is enmeshed in the world’s ecology. While these entreaties are interesting and relevant, the context provided by Twentieth Century philosophy is missing. Indeed, the pragmatic framework that is currently the focus of attention of these efforts provides some interesting insights into whether AI can learn or deal with knotty social issues The emphasis of this manuscript, however, is the anti-Cartesian maneuver that characterizes much of contemporary theory. This change has enormous impact on the potential of AI. After all, Cartesianism is at the core of digitalization and modern data processing. Accordingly, the importance of this change in philosophical orientation for understanding the mind, facts, learning, and communication is a vital consideration. Basic to this reassessment is that the limits of AI become obvious in the absence of Cartesianism. Throughout the Western intellectual tradition, true knowledge has been viewed to be timeless (Grayling 2019). That is, this information is assumed to be divorced from contexts and other human contingencies. If immersed in these situations, knowledge can never surpass opinion and only supply anecdotal evidence. Therefore, most philosophers sought foundations that are universal to establish firm epistemological and moral principles. Martin Heidegger (1969) refers to this trend as the onto-theological tradition. In many ways, Cartesianism epitomizes this tendency. In fact, the aim of Cartesians is to advance clear and distinct knowledge, severed from opinion and other sources of human error (Bordo 1987). In this regard, these thinkers are not necessarily unique, although their strategy is novel. Rather than speculate about ethereal metaphysical principles, such as Ideas, gods, or cosmic unity, Cartesians make a straightforward proposal known as dualism.\n"
          ]
        }
      ],
      "source": [
        "import contractions\n",
        "\n",
        "expanded_words = []\n",
        "for word in text.split():\n",
        "  # using contractions.fix to expand the shortened words\n",
        "  expanded_words.append(contractions.fix(word))\n",
        "\n",
        "expanded_text = ' '.join(expanded_words)\n",
        "print('Expanded_text: ' + expanded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T37SMFnLKvaC"
      },
      "source": [
        "Removing Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Hw3aVtEKufT",
        "outputId": "311408f2-28e8-4f27-d61a-ece837858923"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['\\ufeffdiscussions', 'about', 'ai', 'abound', '.', 'but', 'critics', 'have', 'begun', 'to', 'recognize', 'that', 'these', 'debates', 'have', 'focused', 'mostly', 'on', 'technical', 'issues', '.', 'that', 'is', ',', 'there', 'are', 'certain', 'problems', 'that', 'need', 'to', 'be', 'addressed', 'and', 'have', 'technical', 'solutions', '.', 'debate', 'rages', ',', 'accordingly', ',', 'about', 'how', 'to', 'resolve', 'these', 'issues', 'and', 'move', 'the', 'applications', 'of', 'ai', 'forward', '.', 'perhaps', 'terry', 'winograd', '(', '1996', ')', 'was', 'correct', 'when', 'he', 'lamented', 'some', 'time', 'ago', 'that', 'interest', 'in', 'philosophy', ',', 'what', 'he', 'calls', 'high', 'theory', ',', 'has', 'dissipated', '.', 'the', 'application', 'of', 'ai', ',', 'nonetheless', ',', 'has', 'pushed', 'the', 'discussion', 'beyond', 'technical', 'devices', 'and', 'their', 'possible', 'uses', '.', 'for', 'example', ',', 'critics', 'have', 'begun', 'to', 'recognize', 'that', 'ai', 'can', 'be', 'quite', 'alienating', '(', 'dreyfus', '1992', ';', 'ritzer', '1993', ')', '.', 'workers', 'at', 'amazon', 'have', 'provided', 'an', 'interesting', 'case', 'study', '.', 'while', 'blaming', 'ai', ',', 'they', 'claim', 'to', 'be', 'overworked', 'and', 'do', 'not', 'stayed', 'employed', 'for', 'long', '.', 'they', 'complain', 'regularly', 'about', 'manipulation', ',', 'stress', ',', 'job', 'insecurity', ',', 'and', 'so', 'on', '.', 'clearly', ',', 'ai', 'is', 'not', 'viewed', 'to', 'be', 'their', 'friend', '(', 'livingstone', '2018', ';', 'vicent', '2019', ')', '.', 'on', 'the', 'other', 'hand', ',', 'ai', 'can', 'be', 'quite', 'dangerous', '.', 'take', 'driverless', 'cars', '!', 'in', 'this', 'application', ',', 'through', 'the', 'use', 'of', 'ai', 'cars', 'can', 'learn', 'how', 'to', 'navigate', 'streets', ',', 'other', 'cars', ',', 'pedestrians', ',', 'and', 'occasionally', 'unanticipated', 'obstacles', '.', 'any', 'failure', 'can', 'result', 'in', 'a', 'catastrophe', ',', 'even', 'death', '.', 'questions', 'about', 'the', 'ability', 'of', 'ai', 'to', 'master', 'truly', 'complex', 'activities—those', 'with', 'fluid', 'or', 'shifting', 'frames—have', 'come', 'to', 'the', 'forefront', '(', 'goodfellow', ',', 'bengio', ',', 'and', 'courville', '2016', ')', '.', 'and', 'what', 'about', 'ethical', 'issues', '?', 'the', 'focus', 'of', 'developing', 'algorithms', ',', 'for', 'example', ',', 'is', 'not', 'necessarily', 'on', 'job', 'loss', 'or', 'intrusions', 'into', 'privacy', '.', 'these', 'issues', 'seems', 'to', 'make', 'context', 'difficult', 'to', 'ignore', '.', 'persons', 'tend', 'to', 'become', 'especially', 'nervous', 'when', 'their', 'jobs', 'or', 'privacy', 'are', 'threatened', '.', 'although', 'alienation', 'and', 'learning', 'involve', 'context', ',', 'the', 'ability', 'to', 'survive', 'and', 'the', 'quality', 'of', 'life', 'seem', 'to', 'go', 'to', 'the', 'heart', 'of', 'the', 'matter', '.', 'the', 'time', 'appears', 'to', 'be', 'ripe', ',', 'accordingly', ',', 'to', 'raise', 'the', 'issue', 'of', 'context', 'in', 'the', 'development', 'of', 'advanced', 'technology', '.', 'shoshana', 'zuboff', '(', '2019', ')', 'strives', 'to', 'initiate', 'this', 'sort', 'of', 'discussion', 'with', 'her', 'recent', 'foray', 'into', 'the', 'impact', 'of', 'late', 'capitalism', 'on', 'ai', '.', 'in', 'this', 'regard', ',', 'kate', 'crawford', '(', '2021', ')', 'strives', 'to', 'move', 'beyond', 'the', '“', 'nowhere', 'spaces', '”', 'where', 'she', 'contends', 'most', 'discussion', 'of', 'ai', 'take', 'place', '.', 'she', 'believes', ',', 'for', 'example', ',', 'that', 'ai', 'is', 'enmeshed', 'in', 'the', 'world', '’', 's', 'ecology', '.', 'while', 'these', 'entreaties', 'are', 'interesting', 'and', 'relevant', ',', 'the', 'context', 'provided', 'by', 'twentieth', 'century', 'philosophy', 'is', 'missing', '.', 'indeed', ',', 'the', 'pragmatic', 'framework', 'that', 'is', 'currently', 'the', 'focus', 'of', 'attention', 'of', 'these', 'efforts', 'provides', 'some', 'interesting', 'insights', 'into', 'whether', 'ai', 'can', 'learn', 'or', 'deal', 'with', 'knotty', 'social', 'issues', 'the', 'emphasis', 'of', 'this', 'manuscript', ',', 'however', ',', 'is', 'the', 'anti-cartesian', 'maneuver', 'that', 'characterizes', 'much', 'of', 'contemporary', 'theory', '.', 'this', 'change', 'has', 'enormous', 'impact', 'on', 'the', 'potential', 'of', 'ai', '.', 'after', 'all', ',', 'cartesianism', 'is', 'at', 'the', 'core', 'of', 'digitalization', 'and', 'modern', 'data', 'processing', '.', 'accordingly', ',', 'the', 'importance', 'of', 'this', 'change', 'in', 'philosophical', 'orientation', 'for', 'understanding', 'the', 'mind', ',', 'facts', ',', 'learning', ',', 'and', 'communication', 'is', 'a', 'vital', 'consideration', '.', 'basic', 'to', 'this', 'reassessment', 'is', 'that', 'the', 'limits', 'of', 'ai', 'become', 'obvious', 'in', 'the', 'absence', 'of', 'cartesianism', '.', 'throughout', 'the', 'western', 'intellectual', 'tradition', ',', 'true', 'knowledge', 'has', 'been', 'viewed', 'to', 'be', 'timeless', '(', 'grayling', '2019', ')', '.', 'that', 'is', ',', 'this', 'information', 'is', 'assumed', 'to', 'be', 'divorced', 'from', 'contexts', 'and', 'other', 'human', 'contingencies', '.', 'if', 'immersed', 'in', 'these', 'situations', ',', 'knowledge', 'can', 'never', 'surpass', 'opinion', 'and', 'only', 'supply', 'anecdotal', 'evidence', '.', 'therefore', ',', 'most', 'philosophers', 'sought', 'foundations', 'that', 'are', 'universal', 'to', 'establish', 'firm', 'epistemological', 'and', 'moral', 'principles', '.', 'martin', 'heidegger', '(', '1969', ')', 'refers', 'to', 'this', 'trend', 'as', 'the', 'onto-theological', 'tradition', '.', 'in', 'many', 'ways', ',', 'cartesianism', 'epitomizes', 'this', 'tendency', '.', 'in', 'fact', ',', 'the', 'aim', 'of', 'cartesians', 'is', 'to', 'advance', 'clear', 'and', 'distinct', 'knowledge', ',', 'severed', 'from', 'opinion', 'and', 'other', 'sources', 'of', 'human', 'error', '(', 'bordo', '1987', ')', '.', 'in', 'this', 'regard', ',', 'these', 'thinkers', 'are', 'not', 'necessarily', 'unique', ',', 'although', 'their', 'strategy', 'is', 'novel', '.', 'rather', 'than', 'speculate', 'about', 'ethereal', 'metaphysical', 'principles', ',', 'such', 'as', 'ideas', ',', 'gods', ',', 'or', 'cosmic', 'unity', ',', 'cartesians', 'make', 'a', 'straightforward', 'proposal', 'known', 'as', 'dualism', '.']\n",
            "['\\ufeffdiscussions', 'ai', 'abound', '.', 'critics', 'begun', 'recognize', 'debates', 'focused', 'mostly', 'technical', 'issues', '.', ',', 'certain', 'problems', 'need', 'addressed', 'technical', 'solutions', '.', 'debate', 'rages', ',', 'accordingly', ',', 'resolve', 'issues', 'move', 'applications', 'ai', 'forward', '.', 'perhaps', 'terry', 'winograd', '(', '1996', ')', 'correct', 'lamented', 'time', 'ago', 'interest', 'philosophy', ',', 'calls', 'high', 'theory', ',', 'dissipated', '.', 'application', 'ai', ',', 'nonetheless', ',', 'pushed', 'discussion', 'beyond', 'technical', 'devices', 'possible', 'uses', '.', 'example', ',', 'critics', 'begun', 'recognize', 'ai', 'quite', 'alienating', '(', 'dreyfus', '1992', ';', 'ritzer', '1993', ')', '.', 'workers', 'amazon', 'provided', 'interesting', 'case', 'study', '.', 'blaming', 'ai', ',', 'claim', 'overworked', 'stayed', 'employed', 'long', '.', 'complain', 'regularly', 'manipulation', ',', 'stress', ',', 'job', 'insecurity', ',', '.', 'clearly', ',', 'ai', 'viewed', 'friend', '(', 'livingstone', '2018', ';', 'vicent', '2019', ')', '.', 'hand', ',', 'ai', 'quite', 'dangerous', '.', 'take', 'driverless', 'cars', '!', 'application', ',', 'use', 'ai', 'cars', 'learn', 'navigate', 'streets', ',', 'cars', ',', 'pedestrians', ',', 'occasionally', 'unanticipated', 'obstacles', '.', 'failure', 'result', 'catastrophe', ',', 'even', 'death', '.', 'questions', 'ability', 'ai', 'master', 'truly', 'complex', 'activities—those', 'fluid', 'shifting', 'frames—have', 'come', 'forefront', '(', 'goodfellow', ',', 'bengio', ',', 'courville', '2016', ')', '.', 'ethical', 'issues', '?', 'focus', 'developing', 'algorithms', ',', 'example', ',', 'necessarily', 'job', 'loss', 'intrusions', 'privacy', '.', 'issues', 'seems', 'make', 'context', 'difficult', 'ignore', '.', 'persons', 'tend', 'become', 'especially', 'nervous', 'jobs', 'privacy', 'threatened', '.', 'although', 'alienation', 'learning', 'involve', 'context', ',', 'ability', 'survive', 'quality', 'life', 'seem', 'go', 'heart', 'matter', '.', 'time', 'appears', 'ripe', ',', 'accordingly', ',', 'raise', 'issue', 'context', 'development', 'advanced', 'technology', '.', 'shoshana', 'zuboff', '(', '2019', ')', 'strives', 'initiate', 'sort', 'discussion', 'recent', 'foray', 'impact', 'late', 'capitalism', 'ai', '.', 'regard', ',', 'kate', 'crawford', '(', '2021', ')', 'strives', 'move', 'beyond', '“', 'nowhere', 'spaces', '”', 'contends', 'discussion', 'ai', 'take', 'place', '.', 'believes', ',', 'example', ',', 'ai', 'enmeshed', 'world', '’', 'ecology', '.', 'entreaties', 'interesting', 'relevant', ',', 'context', 'provided', 'twentieth', 'century', 'philosophy', 'missing', '.', 'indeed', ',', 'pragmatic', 'framework', 'currently', 'focus', 'attention', 'efforts', 'provides', 'interesting', 'insights', 'whether', 'ai', 'learn', 'deal', 'knotty', 'social', 'issues', 'emphasis', 'manuscript', ',', 'however', ',', 'anti-cartesian', 'maneuver', 'characterizes', 'much', 'contemporary', 'theory', '.', 'change', 'enormous', 'impact', 'potential', 'ai', '.', ',', 'cartesianism', 'core', 'digitalization', 'modern', 'data', 'processing', '.', 'accordingly', ',', 'importance', 'change', 'philosophical', 'orientation', 'understanding', 'mind', ',', 'facts', ',', 'learning', ',', 'communication', 'vital', 'consideration', '.', 'basic', 'reassessment', 'limits', 'ai', 'become', 'obvious', 'absence', 'cartesianism', '.', 'throughout', 'western', 'intellectual', 'tradition', ',', 'true', 'knowledge', 'viewed', 'timeless', '(', 'grayling', '2019', ')', '.', ',', 'information', 'assumed', 'divorced', 'contexts', 'human', 'contingencies', '.', 'immersed', 'situations', ',', 'knowledge', 'never', 'surpass', 'opinion', 'supply', 'anecdotal', 'evidence', '.', 'therefore', ',', 'philosophers', 'sought', 'foundations', 'universal', 'establish', 'firm', 'epistemological', 'moral', 'principles', '.', 'martin', 'heidegger', '(', '1969', ')', 'refers', 'trend', 'onto-theological', 'tradition', '.', 'many', 'ways', ',', 'cartesianism', 'epitomizes', 'tendency', '.', 'fact', ',', 'aim', 'cartesians', 'advance', 'clear', 'distinct', 'knowledge', ',', 'severed', 'opinion', 'sources', 'human', 'error', '(', 'bordo', '1987', ')', '.', 'regard', ',', 'thinkers', 'necessarily', 'unique', ',', 'although', 'strategy', 'novel', '.', 'rather', 'speculate', 'ethereal', 'metaphysical', 'principles', ',', 'ideas', ',', 'gods', ',', 'cosmic', 'unity', ',', 'cartesians', 'make', 'straightforward', 'proposal', 'known', 'dualism', '.']\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "filtered_sentence = [w for w in nltk_tokens_word if not w.lower() in stop_words]\n",
        "#with no lower case conversion\n",
        "filtered_sentence = []\n",
        "\n",
        "for w in nltk_tokens_word:\n",
        "    if w not in stop_words:\n",
        "        filtered_sentence.append(w)\n",
        "\n",
        "print(nltk_tokens_word)\n",
        "print(filtered_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8RRwehyLUSb"
      },
      "source": [
        "Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9TaSmZ2LVMR",
        "outputId": "1fc066c8-91d9-4474-cd9a-09e1ec32ce60"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "﻿discussions  :  ﻿discuss\n",
            "about  :  about\n",
            "ai  :  ai\n",
            "abound  :  abound\n",
            ".  :  .\n",
            "but  :  but\n",
            "critics  :  critic\n",
            "have  :  have\n",
            "begun  :  begun\n",
            "to  :  to\n",
            "recognize  :  recogn\n",
            "that  :  that\n",
            "these  :  these\n",
            "debates  :  debat\n",
            "have  :  have\n",
            "focused  :  focus\n",
            "mostly  :  mostli\n",
            "on  :  on\n",
            "technical  :  technic\n",
            "issues  :  issu\n",
            ".  :  .\n",
            "that  :  that\n",
            "is  :  is\n",
            ",  :  ,\n",
            "there  :  there\n",
            "are  :  are\n",
            "certain  :  certain\n",
            "problems  :  problem\n",
            "that  :  that\n",
            "need  :  need\n",
            "to  :  to\n",
            "be  :  be\n",
            "addressed  :  address\n",
            "and  :  and\n",
            "have  :  have\n",
            "technical  :  technic\n",
            "solutions  :  solut\n",
            ".  :  .\n",
            "debate  :  debat\n",
            "rages  :  rage\n",
            ",  :  ,\n",
            "accordingly  :  accordingli\n",
            ",  :  ,\n",
            "about  :  about\n",
            "how  :  how\n",
            "to  :  to\n",
            "resolve  :  resolv\n",
            "these  :  these\n",
            "issues  :  issu\n",
            "and  :  and\n",
            "move  :  move\n",
            "the  :  the\n",
            "applications  :  applic\n",
            "of  :  of\n",
            "ai  :  ai\n",
            "forward  :  forward\n",
            ".  :  .\n",
            "perhaps  :  perhap\n",
            "terry  :  terri\n",
            "winograd  :  winograd\n",
            "(  :  (\n",
            "1996  :  1996\n",
            ")  :  )\n",
            "was  :  wa\n",
            "correct  :  correct\n",
            "when  :  when\n",
            "he  :  he\n",
            "lamented  :  lament\n",
            "some  :  some\n",
            "time  :  time\n",
            "ago  :  ago\n",
            "that  :  that\n",
            "interest  :  interest\n",
            "in  :  in\n",
            "philosophy  :  philosophi\n",
            ",  :  ,\n",
            "what  :  what\n",
            "he  :  he\n",
            "calls  :  call\n",
            "high  :  high\n",
            "theory  :  theori\n",
            ",  :  ,\n",
            "has  :  ha\n",
            "dissipated  :  dissip\n",
            ".  :  .\n",
            "the  :  the\n",
            "application  :  applic\n",
            "of  :  of\n",
            "ai  :  ai\n",
            ",  :  ,\n",
            "nonetheless  :  nonetheless\n",
            ",  :  ,\n",
            "has  :  ha\n",
            "pushed  :  push\n",
            "the  :  the\n",
            "discussion  :  discuss\n",
            "beyond  :  beyond\n",
            "technical  :  technic\n",
            "devices  :  devic\n",
            "and  :  and\n",
            "their  :  their\n",
            "possible  :  possibl\n",
            "uses  :  use\n",
            ".  :  .\n",
            "for  :  for\n",
            "example  :  exampl\n",
            ",  :  ,\n",
            "critics  :  critic\n",
            "have  :  have\n",
            "begun  :  begun\n",
            "to  :  to\n",
            "recognize  :  recogn\n",
            "that  :  that\n",
            "ai  :  ai\n",
            "can  :  can\n",
            "be  :  be\n",
            "quite  :  quit\n",
            "alienating  :  alien\n",
            "(  :  (\n",
            "dreyfus  :  dreyfu\n",
            "1992  :  1992\n",
            ";  :  ;\n",
            "ritzer  :  ritzer\n",
            "1993  :  1993\n",
            ")  :  )\n",
            ".  :  .\n",
            "workers  :  worker\n",
            "at  :  at\n",
            "amazon  :  amazon\n",
            "have  :  have\n",
            "provided  :  provid\n",
            "an  :  an\n",
            "interesting  :  interest\n",
            "case  :  case\n",
            "study  :  studi\n",
            ".  :  .\n",
            "while  :  while\n",
            "blaming  :  blame\n",
            "ai  :  ai\n",
            ",  :  ,\n",
            "they  :  they\n",
            "claim  :  claim\n",
            "to  :  to\n",
            "be  :  be\n",
            "overworked  :  overwork\n",
            "and  :  and\n",
            "do  :  do\n",
            "not  :  not\n",
            "stayed  :  stay\n",
            "employed  :  employ\n",
            "for  :  for\n",
            "long  :  long\n",
            ".  :  .\n",
            "they  :  they\n",
            "complain  :  complain\n",
            "regularly  :  regularli\n",
            "about  :  about\n",
            "manipulation  :  manipul\n",
            ",  :  ,\n",
            "stress  :  stress\n",
            ",  :  ,\n",
            "job  :  job\n",
            "insecurity  :  insecur\n",
            ",  :  ,\n",
            "and  :  and\n",
            "so  :  so\n",
            "on  :  on\n",
            ".  :  .\n",
            "clearly  :  clearli\n",
            ",  :  ,\n",
            "ai  :  ai\n",
            "is  :  is\n",
            "not  :  not\n",
            "viewed  :  view\n",
            "to  :  to\n",
            "be  :  be\n",
            "their  :  their\n",
            "friend  :  friend\n",
            "(  :  (\n",
            "livingstone  :  livingston\n",
            "2018  :  2018\n",
            ";  :  ;\n",
            "vicent  :  vicent\n",
            "2019  :  2019\n",
            ")  :  )\n",
            ".  :  .\n",
            "on  :  on\n",
            "the  :  the\n",
            "other  :  other\n",
            "hand  :  hand\n",
            ",  :  ,\n",
            "ai  :  ai\n",
            "can  :  can\n",
            "be  :  be\n",
            "quite  :  quit\n",
            "dangerous  :  danger\n",
            ".  :  .\n",
            "take  :  take\n",
            "driverless  :  driverless\n",
            "cars  :  car\n",
            "!  :  !\n",
            "in  :  in\n",
            "this  :  thi\n",
            "application  :  applic\n",
            ",  :  ,\n",
            "through  :  through\n",
            "the  :  the\n",
            "use  :  use\n",
            "of  :  of\n",
            "ai  :  ai\n",
            "cars  :  car\n",
            "can  :  can\n",
            "learn  :  learn\n",
            "how  :  how\n",
            "to  :  to\n",
            "navigate  :  navig\n",
            "streets  :  street\n",
            ",  :  ,\n",
            "other  :  other\n",
            "cars  :  car\n",
            ",  :  ,\n",
            "pedestrians  :  pedestrian\n",
            ",  :  ,\n",
            "and  :  and\n",
            "occasionally  :  occasion\n",
            "unanticipated  :  unanticip\n",
            "obstacles  :  obstacl\n",
            ".  :  .\n",
            "any  :  ani\n",
            "failure  :  failur\n",
            "can  :  can\n",
            "result  :  result\n",
            "in  :  in\n",
            "a  :  a\n",
            "catastrophe  :  catastroph\n",
            ",  :  ,\n",
            "even  :  even\n",
            "death  :  death\n",
            ".  :  .\n",
            "questions  :  question\n",
            "about  :  about\n",
            "the  :  the\n",
            "ability  :  abil\n",
            "of  :  of\n",
            "ai  :  ai\n",
            "to  :  to\n",
            "master  :  master\n",
            "truly  :  truli\n",
            "complex  :  complex\n",
            "activities—those  :  activities—thos\n",
            "with  :  with\n",
            "fluid  :  fluid\n",
            "or  :  or\n",
            "shifting  :  shift\n",
            "frames—have  :  frames—hav\n",
            "come  :  come\n",
            "to  :  to\n",
            "the  :  the\n",
            "forefront  :  forefront\n",
            "(  :  (\n",
            "goodfellow  :  goodfellow\n",
            ",  :  ,\n",
            "bengio  :  bengio\n",
            ",  :  ,\n",
            "and  :  and\n",
            "courville  :  courvil\n",
            "2016  :  2016\n",
            ")  :  )\n",
            ".  :  .\n",
            "and  :  and\n",
            "what  :  what\n",
            "about  :  about\n",
            "ethical  :  ethic\n",
            "issues  :  issu\n",
            "?  :  ?\n",
            "the  :  the\n",
            "focus  :  focu\n",
            "of  :  of\n",
            "developing  :  develop\n",
            "algorithms  :  algorithm\n",
            ",  :  ,\n",
            "for  :  for\n",
            "example  :  exampl\n",
            ",  :  ,\n",
            "is  :  is\n",
            "not  :  not\n",
            "necessarily  :  necessarili\n",
            "on  :  on\n",
            "job  :  job\n",
            "loss  :  loss\n",
            "or  :  or\n",
            "intrusions  :  intrus\n",
            "into  :  into\n",
            "privacy  :  privaci\n",
            ".  :  .\n",
            "these  :  these\n",
            "issues  :  issu\n",
            "seems  :  seem\n",
            "to  :  to\n",
            "make  :  make\n",
            "context  :  context\n",
            "difficult  :  difficult\n",
            "to  :  to\n",
            "ignore  :  ignor\n",
            ".  :  .\n",
            "persons  :  person\n",
            "tend  :  tend\n",
            "to  :  to\n",
            "become  :  becom\n",
            "especially  :  especi\n",
            "nervous  :  nervou\n",
            "when  :  when\n",
            "their  :  their\n",
            "jobs  :  job\n",
            "or  :  or\n",
            "privacy  :  privaci\n",
            "are  :  are\n",
            "threatened  :  threaten\n",
            ".  :  .\n",
            "although  :  although\n",
            "alienation  :  alien\n",
            "and  :  and\n",
            "learning  :  learn\n",
            "involve  :  involv\n",
            "context  :  context\n",
            ",  :  ,\n",
            "the  :  the\n",
            "ability  :  abil\n",
            "to  :  to\n",
            "survive  :  surviv\n",
            "and  :  and\n",
            "the  :  the\n",
            "quality  :  qualiti\n",
            "of  :  of\n",
            "life  :  life\n",
            "seem  :  seem\n",
            "to  :  to\n",
            "go  :  go\n",
            "to  :  to\n",
            "the  :  the\n",
            "heart  :  heart\n",
            "of  :  of\n",
            "the  :  the\n",
            "matter  :  matter\n",
            ".  :  .\n",
            "the  :  the\n",
            "time  :  time\n",
            "appears  :  appear\n",
            "to  :  to\n",
            "be  :  be\n",
            "ripe  :  ripe\n",
            ",  :  ,\n",
            "accordingly  :  accordingli\n",
            ",  :  ,\n",
            "to  :  to\n",
            "raise  :  rais\n",
            "the  :  the\n",
            "issue  :  issu\n",
            "of  :  of\n",
            "context  :  context\n",
            "in  :  in\n",
            "the  :  the\n",
            "development  :  develop\n",
            "of  :  of\n",
            "advanced  :  advanc\n",
            "technology  :  technolog\n",
            ".  :  .\n",
            "shoshana  :  shoshana\n",
            "zuboff  :  zuboff\n",
            "(  :  (\n",
            "2019  :  2019\n",
            ")  :  )\n",
            "strives  :  strive\n",
            "to  :  to\n",
            "initiate  :  initi\n",
            "this  :  thi\n",
            "sort  :  sort\n",
            "of  :  of\n",
            "discussion  :  discuss\n",
            "with  :  with\n",
            "her  :  her\n",
            "recent  :  recent\n",
            "foray  :  foray\n",
            "into  :  into\n",
            "the  :  the\n",
            "impact  :  impact\n",
            "of  :  of\n",
            "late  :  late\n",
            "capitalism  :  capit\n",
            "on  :  on\n",
            "ai  :  ai\n",
            ".  :  .\n",
            "in  :  in\n",
            "this  :  thi\n",
            "regard  :  regard\n",
            ",  :  ,\n",
            "kate  :  kate\n",
            "crawford  :  crawford\n",
            "(  :  (\n",
            "2021  :  2021\n",
            ")  :  )\n",
            "strives  :  strive\n",
            "to  :  to\n",
            "move  :  move\n",
            "beyond  :  beyond\n",
            "the  :  the\n",
            "“  :  “\n",
            "nowhere  :  nowher\n",
            "spaces  :  space\n",
            "”  :  ”\n",
            "where  :  where\n",
            "she  :  she\n",
            "contends  :  contend\n",
            "most  :  most\n",
            "discussion  :  discuss\n",
            "of  :  of\n",
            "ai  :  ai\n",
            "take  :  take\n",
            "place  :  place\n",
            ".  :  .\n",
            "she  :  she\n",
            "believes  :  believ\n",
            ",  :  ,\n",
            "for  :  for\n",
            "example  :  exampl\n",
            ",  :  ,\n",
            "that  :  that\n",
            "ai  :  ai\n",
            "is  :  is\n",
            "enmeshed  :  enmesh\n",
            "in  :  in\n",
            "the  :  the\n",
            "world  :  world\n",
            "’  :  ’\n",
            "s  :  s\n",
            "ecology  :  ecolog\n",
            ".  :  .\n",
            "while  :  while\n",
            "these  :  these\n",
            "entreaties  :  entreati\n",
            "are  :  are\n",
            "interesting  :  interest\n",
            "and  :  and\n",
            "relevant  :  relev\n",
            ",  :  ,\n",
            "the  :  the\n",
            "context  :  context\n",
            "provided  :  provid\n",
            "by  :  by\n",
            "twentieth  :  twentieth\n",
            "century  :  centuri\n",
            "philosophy  :  philosophi\n",
            "is  :  is\n",
            "missing  :  miss\n",
            ".  :  .\n",
            "indeed  :  inde\n",
            ",  :  ,\n",
            "the  :  the\n",
            "pragmatic  :  pragmat\n",
            "framework  :  framework\n",
            "that  :  that\n",
            "is  :  is\n",
            "currently  :  current\n",
            "the  :  the\n",
            "focus  :  focu\n",
            "of  :  of\n",
            "attention  :  attent\n",
            "of  :  of\n",
            "these  :  these\n",
            "efforts  :  effort\n",
            "provides  :  provid\n",
            "some  :  some\n",
            "interesting  :  interest\n",
            "insights  :  insight\n",
            "into  :  into\n",
            "whether  :  whether\n",
            "ai  :  ai\n",
            "can  :  can\n",
            "learn  :  learn\n",
            "or  :  or\n",
            "deal  :  deal\n",
            "with  :  with\n",
            "knotty  :  knotti\n",
            "social  :  social\n",
            "issues  :  issu\n",
            "the  :  the\n",
            "emphasis  :  emphasi\n",
            "of  :  of\n",
            "this  :  thi\n",
            "manuscript  :  manuscript\n",
            ",  :  ,\n",
            "however  :  howev\n",
            ",  :  ,\n",
            "is  :  is\n",
            "the  :  the\n",
            "anti-cartesian  :  anti-cartesian\n",
            "maneuver  :  maneuv\n",
            "that  :  that\n",
            "characterizes  :  character\n",
            "much  :  much\n",
            "of  :  of\n",
            "contemporary  :  contemporari\n",
            "theory  :  theori\n",
            ".  :  .\n",
            "this  :  thi\n",
            "change  :  chang\n",
            "has  :  ha\n",
            "enormous  :  enorm\n",
            "impact  :  impact\n",
            "on  :  on\n",
            "the  :  the\n",
            "potential  :  potenti\n",
            "of  :  of\n",
            "ai  :  ai\n",
            ".  :  .\n",
            "after  :  after\n",
            "all  :  all\n",
            ",  :  ,\n",
            "cartesianism  :  cartesian\n",
            "is  :  is\n",
            "at  :  at\n",
            "the  :  the\n",
            "core  :  core\n",
            "of  :  of\n",
            "digitalization  :  digit\n",
            "and  :  and\n",
            "modern  :  modern\n",
            "data  :  data\n",
            "processing  :  process\n",
            ".  :  .\n",
            "accordingly  :  accordingli\n",
            ",  :  ,\n",
            "the  :  the\n",
            "importance  :  import\n",
            "of  :  of\n",
            "this  :  thi\n",
            "change  :  chang\n",
            "in  :  in\n",
            "philosophical  :  philosoph\n",
            "orientation  :  orient\n",
            "for  :  for\n",
            "understanding  :  understand\n",
            "the  :  the\n",
            "mind  :  mind\n",
            ",  :  ,\n",
            "facts  :  fact\n",
            ",  :  ,\n",
            "learning  :  learn\n",
            ",  :  ,\n",
            "and  :  and\n",
            "communication  :  commun\n",
            "is  :  is\n",
            "a  :  a\n",
            "vital  :  vital\n",
            "consideration  :  consider\n",
            ".  :  .\n",
            "basic  :  basic\n",
            "to  :  to\n",
            "this  :  thi\n",
            "reassessment  :  reassess\n",
            "is  :  is\n",
            "that  :  that\n",
            "the  :  the\n",
            "limits  :  limit\n",
            "of  :  of\n",
            "ai  :  ai\n",
            "become  :  becom\n",
            "obvious  :  obviou\n",
            "in  :  in\n",
            "the  :  the\n",
            "absence  :  absenc\n",
            "of  :  of\n",
            "cartesianism  :  cartesian\n",
            ".  :  .\n",
            "throughout  :  throughout\n",
            "the  :  the\n",
            "western  :  western\n",
            "intellectual  :  intellectu\n",
            "tradition  :  tradit\n",
            ",  :  ,\n",
            "true  :  true\n",
            "knowledge  :  knowledg\n",
            "has  :  ha\n",
            "been  :  been\n",
            "viewed  :  view\n",
            "to  :  to\n",
            "be  :  be\n",
            "timeless  :  timeless\n",
            "(  :  (\n",
            "grayling  :  grayl\n",
            "2019  :  2019\n",
            ")  :  )\n",
            ".  :  .\n",
            "that  :  that\n",
            "is  :  is\n",
            ",  :  ,\n",
            "this  :  thi\n",
            "information  :  inform\n",
            "is  :  is\n",
            "assumed  :  assum\n",
            "to  :  to\n",
            "be  :  be\n",
            "divorced  :  divorc\n",
            "from  :  from\n",
            "contexts  :  context\n",
            "and  :  and\n",
            "other  :  other\n",
            "human  :  human\n",
            "contingencies  :  conting\n",
            ".  :  .\n",
            "if  :  if\n",
            "immersed  :  immers\n",
            "in  :  in\n",
            "these  :  these\n",
            "situations  :  situat\n",
            ",  :  ,\n",
            "knowledge  :  knowledg\n",
            "can  :  can\n",
            "never  :  never\n",
            "surpass  :  surpass\n",
            "opinion  :  opinion\n",
            "and  :  and\n",
            "only  :  onli\n",
            "supply  :  suppli\n",
            "anecdotal  :  anecdot\n",
            "evidence  :  evid\n",
            ".  :  .\n",
            "therefore  :  therefor\n",
            ",  :  ,\n",
            "most  :  most\n",
            "philosophers  :  philosoph\n",
            "sought  :  sought\n",
            "foundations  :  foundat\n",
            "that  :  that\n",
            "are  :  are\n",
            "universal  :  univers\n",
            "to  :  to\n",
            "establish  :  establish\n",
            "firm  :  firm\n",
            "epistemological  :  epistemolog\n",
            "and  :  and\n",
            "moral  :  moral\n",
            "principles  :  principl\n",
            ".  :  .\n",
            "martin  :  martin\n",
            "heidegger  :  heidegg\n",
            "(  :  (\n",
            "1969  :  1969\n",
            ")  :  )\n",
            "refers  :  refer\n",
            "to  :  to\n",
            "this  :  thi\n",
            "trend  :  trend\n",
            "as  :  as\n",
            "the  :  the\n",
            "onto-theological  :  onto-theolog\n",
            "tradition  :  tradit\n",
            ".  :  .\n",
            "in  :  in\n",
            "many  :  mani\n",
            "ways  :  way\n",
            ",  :  ,\n",
            "cartesianism  :  cartesian\n",
            "epitomizes  :  epitom\n",
            "this  :  thi\n",
            "tendency  :  tendenc\n",
            ".  :  .\n",
            "in  :  in\n",
            "fact  :  fact\n",
            ",  :  ,\n",
            "the  :  the\n",
            "aim  :  aim\n",
            "of  :  of\n",
            "cartesians  :  cartesian\n",
            "is  :  is\n",
            "to  :  to\n",
            "advance  :  advanc\n",
            "clear  :  clear\n",
            "and  :  and\n",
            "distinct  :  distinct\n",
            "knowledge  :  knowledg\n",
            ",  :  ,\n",
            "severed  :  sever\n",
            "from  :  from\n",
            "opinion  :  opinion\n",
            "and  :  and\n",
            "other  :  other\n",
            "sources  :  sourc\n",
            "of  :  of\n",
            "human  :  human\n",
            "error  :  error\n",
            "(  :  (\n",
            "bordo  :  bordo\n",
            "1987  :  1987\n",
            ")  :  )\n",
            ".  :  .\n",
            "in  :  in\n",
            "this  :  thi\n",
            "regard  :  regard\n",
            ",  :  ,\n",
            "these  :  these\n",
            "thinkers  :  thinker\n",
            "are  :  are\n",
            "not  :  not\n",
            "necessarily  :  necessarili\n",
            "unique  :  uniqu\n",
            ",  :  ,\n",
            "although  :  although\n",
            "their  :  their\n",
            "strategy  :  strategi\n",
            "is  :  is\n",
            "novel  :  novel\n",
            ".  :  .\n",
            "rather  :  rather\n",
            "than  :  than\n",
            "speculate  :  specul\n",
            "about  :  about\n",
            "ethereal  :  ether\n",
            "metaphysical  :  metaphys\n",
            "principles  :  principl\n",
            ",  :  ,\n",
            "such  :  such\n",
            "as  :  as\n",
            "ideas  :  idea\n",
            ",  :  ,\n",
            "gods  :  god\n",
            ",  :  ,\n",
            "or  :  or\n",
            "cosmic  :  cosmic\n",
            "unity  :  uniti\n",
            ",  :  ,\n",
            "cartesians  :  cartesian\n",
            "make  :  make\n",
            "a  :  a\n",
            "straightforward  :  straightforward\n",
            "proposal  :  propos\n",
            "known  :  known\n",
            "as  :  as\n",
            "dualism  :  dualism\n",
            ".  :  .\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "ps = PorterStemmer()\n",
        "\n",
        "for w in nltk_tokens_word:\n",
        "    print(w, \" : \", ps.stem(w))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUsj6RpuLdL6",
        "outputId": "7b8ac708-cbf9-40b5-d61a-7bc27656d53b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--Word--            --Stem--            \n",
            "﻿discussions        ﻿discussions        \n",
            "about               about               \n",
            "ai                  ai                  \n",
            "abound              abound              \n",
            ".                   .                   \n",
            "but                 but                 \n",
            "critics             critics             \n",
            "have                have                \n",
            "begun               begin               \n",
            "to                  to                  \n",
            "recognize           recognize           \n",
            "that                that                \n",
            "these               these               \n",
            "debates             debate              \n",
            "have                have                \n",
            "focused             focus               \n",
            "mostly              mostly              \n",
            "on                  on                  \n",
            "technical           technical           \n",
            "issues              issue               \n",
            ".                   .                   \n",
            "that                that                \n",
            "is                  be                  \n",
            ",                   ,                   \n",
            "there               there               \n",
            "are                 be                  \n",
            "certain             certain             \n",
            "problems            problems            \n",
            "that                that                \n",
            "need                need                \n",
            "to                  to                  \n",
            "be                  be                  \n",
            "addressed           address             \n",
            "and                 and                 \n",
            "have                have                \n",
            "technical           technical           \n",
            "solutions           solutions           \n",
            ".                   .                   \n",
            "debate              debate              \n",
            "rages               rag                 \n",
            ",                   ,                   \n",
            "accordingly         accordingly         \n",
            ",                   ,                   \n",
            "about               about               \n",
            "how                 how                 \n",
            "to                  to                  \n",
            "resolve             resolve             \n",
            "these               these               \n",
            "issues              issue               \n",
            "and                 and                 \n",
            "move                move                \n",
            "the                 the                 \n",
            "applications        applications        \n",
            "of                  of                  \n",
            "ai                  ai                  \n",
            "forward             forward             \n",
            ".                   .                   \n",
            "perhaps             perhaps             \n",
            "terry               terry               \n",
            "winograd            winograd            \n",
            "(                   (                   \n",
            "1996                1996                \n",
            ")                   )                   \n",
            "was                 be                  \n",
            "correct             correct             \n",
            "when                when                \n",
            "he                  he                  \n",
            "lamented            lament              \n",
            "some                some                \n",
            "time                time                \n",
            "ago                 ago                 \n",
            "that                that                \n",
            "interest            interest            \n",
            "in                  in                  \n",
            "philosophy          philosophy          \n",
            ",                   ,                   \n",
            "what                what                \n",
            "he                  he                  \n",
            "calls               call                \n",
            "high                high                \n",
            "theory              theory              \n",
            ",                   ,                   \n",
            "has                 have                \n",
            "dissipated          dissipate           \n",
            ".                   .                   \n",
            "the                 the                 \n",
            "application         application         \n",
            "of                  of                  \n",
            "ai                  ai                  \n",
            ",                   ,                   \n",
            "nonetheless         nonetheless         \n",
            ",                   ,                   \n",
            "has                 have                \n",
            "pushed              push                \n",
            "the                 the                 \n",
            "discussion          discussion          \n",
            "beyond              beyond              \n",
            "technical           technical           \n",
            "devices             devices             \n",
            "and                 and                 \n",
            "their               their               \n",
            "possible            possible            \n",
            "uses                use                 \n",
            ".                   .                   \n",
            "for                 for                 \n",
            "example             example             \n",
            ",                   ,                   \n",
            "critics             critics             \n",
            "have                have                \n",
            "begun               begin               \n",
            "to                  to                  \n",
            "recognize           recognize           \n",
            "that                that                \n",
            "ai                  ai                  \n",
            "can                 can                 \n",
            "be                  be                  \n",
            "quite               quite               \n",
            "alienating          alienate            \n",
            "(                   (                   \n",
            "dreyfus             dreyfus             \n",
            "1992                1992                \n",
            ";                   ;                   \n",
            "ritzer              ritzer              \n",
            "1993                1993                \n",
            ")                   )                   \n",
            ".                   .                   \n",
            "workers             workers             \n",
            "at                  at                  \n",
            "amazon              amazon              \n",
            "have                have                \n",
            "provided            provide             \n",
            "an                  an                  \n",
            "interesting         interest            \n",
            "case                case                \n",
            "study               study               \n",
            ".                   .                   \n",
            "while               while               \n",
            "blaming             blame               \n",
            "ai                  ai                  \n",
            ",                   ,                   \n",
            "they                they                \n",
            "claim               claim               \n",
            "to                  to                  \n",
            "be                  be                  \n",
            "overworked          overwork            \n",
            "and                 and                 \n",
            "do                  do                  \n",
            "not                 not                 \n",
            "stayed              stay                \n",
            "employed            employ              \n",
            "for                 for                 \n",
            "long                long                \n",
            ".                   .                   \n",
            "they                they                \n",
            "complain            complain            \n",
            "regularly           regularly           \n",
            "about               about               \n",
            "manipulation        manipulation        \n",
            ",                   ,                   \n",
            "stress              stress              \n",
            ",                   ,                   \n",
            "job                 job                 \n",
            "insecurity          insecurity          \n",
            ",                   ,                   \n",
            "and                 and                 \n",
            "so                  so                  \n",
            "on                  on                  \n",
            ".                   .                   \n",
            "clearly             clearly             \n",
            ",                   ,                   \n",
            "ai                  ai                  \n",
            "is                  be                  \n",
            "not                 not                 \n",
            "viewed              view                \n",
            "to                  to                  \n",
            "be                  be                  \n",
            "their               their               \n",
            "friend              friend              \n",
            "(                   (                   \n",
            "livingstone         livingstone         \n",
            "2018                2018                \n",
            ";                   ;                   \n",
            "vicent              vicent              \n",
            "2019                2019                \n",
            ")                   )                   \n",
            ".                   .                   \n",
            "on                  on                  \n",
            "the                 the                 \n",
            "other               other               \n",
            "hand                hand                \n",
            ",                   ,                   \n",
            "ai                  ai                  \n",
            "can                 can                 \n",
            "be                  be                  \n",
            "quite               quite               \n",
            "dangerous           dangerous           \n",
            ".                   .                   \n",
            "take                take                \n",
            "driverless          driverless          \n",
            "cars                cars                \n",
            "!                   !                   \n",
            "in                  in                  \n",
            "this                this                \n",
            "application         application         \n",
            ",                   ,                   \n",
            "through             through             \n",
            "the                 the                 \n",
            "use                 use                 \n",
            "of                  of                  \n",
            "ai                  ai                  \n",
            "cars                cars                \n",
            "can                 can                 \n",
            "learn               learn               \n",
            "how                 how                 \n",
            "to                  to                  \n",
            "navigate            navigate            \n",
            "streets             streets             \n",
            ",                   ,                   \n",
            "other               other               \n",
            "cars                cars                \n",
            ",                   ,                   \n",
            "pedestrians         pedestrians         \n",
            ",                   ,                   \n",
            "and                 and                 \n",
            "occasionally        occasionally        \n",
            "unanticipated       unanticipated       \n",
            "obstacles           obstacles           \n",
            ".                   .                   \n",
            "any                 any                 \n",
            "failure             failure             \n",
            "can                 can                 \n",
            "result              result              \n",
            "in                  in                  \n",
            "a                   a                   \n",
            "catastrophe         catastrophe         \n",
            ",                   ,                   \n",
            "even                even                \n",
            "death               death               \n",
            ".                   .                   \n",
            "questions           question            \n",
            "about               about               \n",
            "the                 the                 \n",
            "ability             ability             \n",
            "of                  of                  \n",
            "ai                  ai                  \n",
            "to                  to                  \n",
            "master              master              \n",
            "truly               truly               \n",
            "complex             complex             \n",
            "activities—those    activities—those    \n",
            "with                with                \n",
            "fluid               fluid               \n",
            "or                  or                  \n",
            "shifting            shift               \n",
            "frames—have         frames—have         \n",
            "come                come                \n",
            "to                  to                  \n",
            "the                 the                 \n",
            "forefront           forefront           \n",
            "(                   (                   \n",
            "goodfellow          goodfellow          \n",
            ",                   ,                   \n",
            "bengio              bengio              \n",
            ",                   ,                   \n",
            "and                 and                 \n",
            "courville           courville           \n",
            "2016                2016                \n",
            ")                   )                   \n",
            ".                   .                   \n",
            "and                 and                 \n",
            "what                what                \n",
            "about               about               \n",
            "ethical             ethical             \n",
            "issues              issue               \n",
            "?                   ?                   \n",
            "the                 the                 \n",
            "focus               focus               \n",
            "of                  of                  \n",
            "developing          develop             \n",
            "algorithms          algorithms          \n",
            ",                   ,                   \n",
            "for                 for                 \n",
            "example             example             \n",
            ",                   ,                   \n",
            "is                  be                  \n",
            "not                 not                 \n",
            "necessarily         necessarily         \n",
            "on                  on                  \n",
            "job                 job                 \n",
            "loss                loss                \n",
            "or                  or                  \n",
            "intrusions          intrusions          \n",
            "into                into                \n",
            "privacy             privacy             \n",
            ".                   .                   \n",
            "these               these               \n",
            "issues              issue               \n",
            "seems               seem                \n",
            "to                  to                  \n",
            "make                make                \n",
            "context             context             \n",
            "difficult           difficult           \n",
            "to                  to                  \n",
            "ignore              ignore              \n",
            ".                   .                   \n",
            "persons             persons             \n",
            "tend                tend                \n",
            "to                  to                  \n",
            "become              become              \n",
            "especially          especially          \n",
            "nervous             nervous             \n",
            "when                when                \n",
            "their               their               \n",
            "jobs                job                 \n",
            "or                  or                  \n",
            "privacy             privacy             \n",
            "are                 be                  \n",
            "threatened          threaten            \n",
            ".                   .                   \n",
            "although            although            \n",
            "alienation          alienation          \n",
            "and                 and                 \n",
            "learning            learn               \n",
            "involve             involve             \n",
            "context             context             \n",
            ",                   ,                   \n",
            "the                 the                 \n",
            "ability             ability             \n",
            "to                  to                  \n",
            "survive             survive             \n",
            "and                 and                 \n",
            "the                 the                 \n",
            "quality             quality             \n",
            "of                  of                  \n",
            "life                life                \n",
            "seem                seem                \n",
            "to                  to                  \n",
            "go                  go                  \n",
            "to                  to                  \n",
            "the                 the                 \n",
            "heart               heart               \n",
            "of                  of                  \n",
            "the                 the                 \n",
            "matter              matter              \n",
            ".                   .                   \n",
            "the                 the                 \n",
            "time                time                \n",
            "appears             appear              \n",
            "to                  to                  \n",
            "be                  be                  \n",
            "ripe                ripe                \n",
            ",                   ,                   \n",
            "accordingly         accordingly         \n",
            ",                   ,                   \n",
            "to                  to                  \n",
            "raise               raise               \n",
            "the                 the                 \n",
            "issue               issue               \n",
            "of                  of                  \n",
            "context             context             \n",
            "in                  in                  \n",
            "the                 the                 \n",
            "development         development         \n",
            "of                  of                  \n",
            "advanced            advance             \n",
            "technology          technology          \n",
            ".                   .                   \n",
            "shoshana            shoshana            \n",
            "zuboff              zuboff              \n",
            "(                   (                   \n",
            "2019                2019                \n",
            ")                   )                   \n",
            "strives             strive              \n",
            "to                  to                  \n",
            "initiate            initiate            \n",
            "this                this                \n",
            "sort                sort                \n",
            "of                  of                  \n",
            "discussion          discussion          \n",
            "with                with                \n",
            "her                 her                 \n",
            "recent              recent              \n",
            "foray               foray               \n",
            "into                into                \n",
            "the                 the                 \n",
            "impact              impact              \n",
            "of                  of                  \n",
            "late                late                \n",
            "capitalism          capitalism          \n",
            "on                  on                  \n",
            "ai                  ai                  \n",
            ".                   .                   \n",
            "in                  in                  \n",
            "this                this                \n",
            "regard              regard              \n",
            ",                   ,                   \n",
            "kate                kate                \n",
            "crawford            crawford            \n",
            "(                   (                   \n",
            "2021                2021                \n",
            ")                   )                   \n",
            "strives             strive              \n",
            "to                  to                  \n",
            "move                move                \n",
            "beyond              beyond              \n",
            "the                 the                 \n",
            "“                   “                   \n",
            "nowhere             nowhere             \n",
            "spaces              space               \n",
            "”                   ”                   \n",
            "where               where               \n",
            "she                 she                 \n",
            "contends            contend             \n",
            "most                most                \n",
            "discussion          discussion          \n",
            "of                  of                  \n",
            "ai                  ai                  \n",
            "take                take                \n",
            "place               place               \n",
            ".                   .                   \n",
            "she                 she                 \n",
            "believes            believe             \n",
            ",                   ,                   \n",
            "for                 for                 \n",
            "example             example             \n",
            ",                   ,                   \n",
            "that                that                \n",
            "ai                  ai                  \n",
            "is                  be                  \n",
            "enmeshed            enmesh              \n",
            "in                  in                  \n",
            "the                 the                 \n",
            "world               world               \n",
            "’                   ’                   \n",
            "s                   s                   \n",
            "ecology             ecology             \n",
            ".                   .                   \n",
            "while               while               \n",
            "these               these               \n",
            "entreaties          entreaties          \n",
            "are                 be                  \n",
            "interesting         interest            \n",
            "and                 and                 \n",
            "relevant            relevant            \n",
            ",                   ,                   \n",
            "the                 the                 \n",
            "context             context             \n",
            "provided            provide             \n",
            "by                  by                  \n",
            "twentieth           twentieth           \n",
            "century             century             \n",
            "philosophy          philosophy          \n",
            "is                  be                  \n",
            "missing             miss                \n",
            ".                   .                   \n",
            "indeed              indeed              \n",
            ",                   ,                   \n",
            "the                 the                 \n",
            "pragmatic           pragmatic           \n",
            "framework           framework           \n",
            "that                that                \n",
            "is                  be                  \n",
            "currently           currently           \n",
            "the                 the                 \n",
            "focus               focus               \n",
            "of                  of                  \n",
            "attention           attention           \n",
            "of                  of                  \n",
            "these               these               \n",
            "efforts             efforts             \n",
            "provides            provide             \n",
            "some                some                \n",
            "interesting         interest            \n",
            "insights            insights            \n",
            "into                into                \n",
            "whether             whether             \n",
            "ai                  ai                  \n",
            "can                 can                 \n",
            "learn               learn               \n",
            "or                  or                  \n",
            "deal                deal                \n",
            "with                with                \n",
            "knotty              knotty              \n",
            "social              social              \n",
            "issues              issue               \n",
            "the                 the                 \n",
            "emphasis            emphasis            \n",
            "of                  of                  \n",
            "this                this                \n",
            "manuscript          manuscript          \n",
            ",                   ,                   \n",
            "however             however             \n",
            ",                   ,                   \n",
            "is                  be                  \n",
            "the                 the                 \n",
            "anti-cartesian      anti-cartesian      \n",
            "maneuver            maneuver            \n",
            "that                that                \n",
            "characterizes       characterize        \n",
            "much                much                \n",
            "of                  of                  \n",
            "contemporary        contemporary        \n",
            "theory              theory              \n",
            ".                   .                   \n",
            "this                this                \n",
            "change              change              \n",
            "has                 have                \n",
            "enormous            enormous            \n",
            "impact              impact              \n",
            "on                  on                  \n",
            "the                 the                 \n",
            "potential           potential           \n",
            "of                  of                  \n",
            "ai                  ai                  \n",
            ".                   .                   \n",
            "after               after               \n",
            "all                 all                 \n",
            ",                   ,                   \n",
            "cartesianism        cartesianism        \n",
            "is                  be                  \n",
            "at                  at                  \n",
            "the                 the                 \n",
            "core                core                \n",
            "of                  of                  \n",
            "digitalization      digitalization      \n",
            "and                 and                 \n",
            "modern              modern              \n",
            "data                data                \n",
            "processing          process             \n",
            ".                   .                   \n",
            "accordingly         accordingly         \n",
            ",                   ,                   \n",
            "the                 the                 \n",
            "importance          importance          \n",
            "of                  of                  \n",
            "this                this                \n",
            "change              change              \n",
            "in                  in                  \n",
            "philosophical       philosophical       \n",
            "orientation         orientation         \n",
            "for                 for                 \n",
            "understanding       understand          \n",
            "the                 the                 \n",
            "mind                mind                \n",
            ",                   ,                   \n",
            "facts               facts               \n",
            ",                   ,                   \n",
            "learning            learn               \n",
            ",                   ,                   \n",
            "and                 and                 \n",
            "communication       communication       \n",
            "is                  be                  \n",
            "a                   a                   \n",
            "vital               vital               \n",
            "consideration       consideration       \n",
            ".                   .                   \n",
            "basic               basic               \n",
            "to                  to                  \n",
            "this                this                \n",
            "reassessment        reassessment        \n",
            "is                  be                  \n",
            "that                that                \n",
            "the                 the                 \n",
            "limits              limit               \n",
            "of                  of                  \n",
            "ai                  ai                  \n",
            "become              become              \n",
            "obvious             obvious             \n",
            "in                  in                  \n",
            "the                 the                 \n",
            "absence             absence             \n",
            "of                  of                  \n",
            "cartesianism        cartesianism        \n",
            ".                   .                   \n",
            "throughout          throughout          \n",
            "the                 the                 \n",
            "western             western             \n",
            "intellectual        intellectual        \n",
            "tradition           tradition           \n",
            ",                   ,                   \n",
            "true                true                \n",
            "knowledge           knowledge           \n",
            "has                 have                \n",
            "been                be                  \n",
            "viewed              view                \n",
            "to                  to                  \n",
            "be                  be                  \n",
            "timeless            timeless            \n",
            "(                   (                   \n",
            "grayling            grayling            \n",
            "2019                2019                \n",
            ")                   )                   \n",
            ".                   .                   \n",
            "that                that                \n",
            "is                  be                  \n",
            ",                   ,                   \n",
            "this                this                \n",
            "information         information         \n",
            "is                  be                  \n",
            "assumed             assume              \n",
            "to                  to                  \n",
            "be                  be                  \n",
            "divorced            divorce             \n",
            "from                from                \n",
            "contexts            contexts            \n",
            "and                 and                 \n",
            "other               other               \n",
            "human               human               \n",
            "contingencies       contingencies       \n",
            ".                   .                   \n",
            "if                  if                  \n",
            "immersed            immerse             \n",
            "in                  in                  \n",
            "these               these               \n",
            "situations          situations          \n",
            ",                   ,                   \n",
            "knowledge           knowledge           \n",
            "can                 can                 \n",
            "never               never               \n",
            "surpass             surpass             \n",
            "opinion             opinion             \n",
            "and                 and                 \n",
            "only                only                \n",
            "supply              supply              \n",
            "anecdotal           anecdotal           \n",
            "evidence            evidence            \n",
            ".                   .                   \n",
            "therefore           therefore           \n",
            ",                   ,                   \n",
            "most                most                \n",
            "philosophers        philosophers        \n",
            "sought              seek                \n",
            "foundations         foundations         \n",
            "that                that                \n",
            "are                 be                  \n",
            "universal           universal           \n",
            "to                  to                  \n",
            "establish           establish           \n",
            "firm                firm                \n",
            "epistemological     epistemological     \n",
            "and                 and                 \n",
            "moral               moral               \n",
            "principles          principles          \n",
            ".                   .                   \n",
            "martin              martin              \n",
            "heidegger           heidegger           \n",
            "(                   (                   \n",
            "1969                1969                \n",
            ")                   )                   \n",
            "refers              refer               \n",
            "to                  to                  \n",
            "this                this                \n",
            "trend               trend               \n",
            "as                  as                  \n",
            "the                 the                 \n",
            "onto-theological    onto-theological    \n",
            "tradition           tradition           \n",
            ".                   .                   \n",
            "in                  in                  \n",
            "many                many                \n",
            "ways                ways                \n",
            ",                   ,                   \n",
            "cartesianism        cartesianism        \n",
            "epitomizes          epitomize           \n",
            "this                this                \n",
            "tendency            tendency            \n",
            ".                   .                   \n",
            "in                  in                  \n",
            "fact                fact                \n",
            ",                   ,                   \n",
            "the                 the                 \n",
            "aim                 aim                 \n",
            "of                  of                  \n",
            "cartesians          cartesians          \n",
            "is                  be                  \n",
            "to                  to                  \n",
            "advance             advance             \n",
            "clear               clear               \n",
            "and                 and                 \n",
            "distinct            distinct            \n",
            "knowledge           knowledge           \n",
            ",                   ,                   \n",
            "severed             sever               \n",
            "from                from                \n",
            "opinion             opinion             \n",
            "and                 and                 \n",
            "other               other               \n",
            "sources             source              \n",
            "of                  of                  \n",
            "human               human               \n",
            "error               error               \n",
            "(                   (                   \n",
            "bordo               bordo               \n",
            "1987                1987                \n",
            ")                   )                   \n",
            ".                   .                   \n",
            "in                  in                  \n",
            "this                this                \n",
            "regard              regard              \n",
            ",                   ,                   \n",
            "these               these               \n",
            "thinkers            thinkers            \n",
            "are                 be                  \n",
            "not                 not                 \n",
            "necessarily         necessarily         \n",
            "unique              unique              \n",
            ",                   ,                   \n",
            "although            although            \n",
            "their               their               \n",
            "strategy            strategy            \n",
            "is                  be                  \n",
            "novel               novel               \n",
            ".                   .                   \n",
            "rather              rather              \n",
            "than                than                \n",
            "speculate           speculate           \n",
            "about               about               \n",
            "ethereal            ethereal            \n",
            "metaphysical        metaphysical        \n",
            "principles          principles          \n",
            ",                   ,                   \n",
            "such                such                \n",
            "as                  as                  \n",
            "ideas               ideas               \n",
            ",                   ,                   \n",
            "gods                gods                \n",
            ",                   ,                   \n",
            "or                  or                  \n",
            "cosmic              cosmic              \n",
            "unity               unity               \n",
            ",                   ,                   \n",
            "cartesians          cartesians          \n",
            "make                make                \n",
            "a                   a                   \n",
            "straightforward     straightforward     \n",
            "proposal            proposal            \n",
            "known               know                \n",
            "as                  as                  \n",
            "dualism             dualism             \n",
            ".                   .                   \n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "\n",
        "wnl = WordNetLemmatizer()\n",
        "# Example inflections to reduce\n",
        "# Perform lemmatization\n",
        "print(\"{0:20}{1:20}\".format(\"--Word--\",\"--Stem--\"))\n",
        "for word in nltk_tokens_word:\n",
        "   print (\"{0:20}{1:20}\".format(word, wnl.lemmatize(word, pos=\"v\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aJqnv7JMD9i",
        "outputId": "6d8c058a-b881-43bb-9568-226cd0c77804"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 98)\t1.0\n",
            "  (1, 11)\t1.0\n",
            "  (2, 20)\t1.0\n",
            "  (3, 10)\t1.0\n",
            "  (5, 51)\t1.0\n",
            "  (6, 84)\t1.0\n",
            "  (7, 145)\t1.0\n",
            "  (8, 45)\t1.0\n",
            "  (9, 314)\t1.0\n",
            "  (10, 254)\t1.0\n",
            "  (11, 297)\t1.0\n",
            "  (12, 304)\t1.0\n",
            "  (13, 91)\t1.0\n",
            "  (14, 145)\t1.0\n",
            "  (15, 129)\t1.0\n",
            "  (16, 204)\t1.0\n",
            "  (17, 220)\t1.0\n",
            "  (18, 291)\t1.0\n",
            "  (19, 174)\t1.0\n",
            "  (21, 297)\t1.0\n",
            "  (22, 172)\t1.0\n",
            "  (24, 302)\t1.0\n",
            "  (25, 36)\t1.0\n",
            "  (26, 63)\t1.0\n",
            "  (27, 240)\t1.0\n",
            "  :\t:\n",
            "  (708, 299)\t1.0\n",
            "  (709, 281)\t1.0\n",
            "  (710, 172)\t1.0\n",
            "  (711, 214)\t1.0\n",
            "  (713, 251)\t1.0\n",
            "  (714, 296)\t1.0\n",
            "  (715, 278)\t1.0\n",
            "  (716, 11)\t1.0\n",
            "  (717, 118)\t1.0\n",
            "  (718, 198)\t1.0\n",
            "  (719, 238)\t1.0\n",
            "  (721, 286)\t1.0\n",
            "  (722, 37)\t1.0\n",
            "  (723, 154)\t1.0\n",
            "  (725, 140)\t1.0\n",
            "  (727, 224)\t1.0\n",
            "  (728, 81)\t1.0\n",
            "  (729, 323)\t1.0\n",
            "  (731, 59)\t1.0\n",
            "  (732, 190)\t1.0\n",
            "  (734, 280)\t1.0\n",
            "  (735, 242)\t1.0\n",
            "  (736, 180)\t1.0\n",
            "  (737, 37)\t1.0\n",
            "  (738, 105)\t1.0\n"
          ]
        }
      ],
      "source": [
        "vect = TfidfVectorizer().fit(nltk_tokens_word)\n",
        "X = vect.transform(nltk_tokens_word)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHBEmJnAMu2n",
        "outputId": "ad33301b-b7f5-40c2-9782-42b60347f12f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1996\n",
            "1992\n",
            "1993\n",
            "2018\n",
            "2019\n",
            "2016\n",
            "2019\n",
            "2021\n",
            "2019\n",
            "1969\n",
            "1987\n"
          ]
        }
      ],
      "source": [
        "for case in nltk_tokens_word:\n",
        "    if case.isnumeric():\n",
        "        print(case)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbIliEXfQ9aB"
      },
      "source": [
        "TF,IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbZ4-BikQ4ap",
        "outputId": "563d5ab4-f880-46e8-eca1-56f55f8abc99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 98)\t0.6077963696418514\n",
            "  (0, 20)\t0.29343232710714984\n",
            "  (0, 11)\t0.41840723644417843\n",
            "  (0, 10)\t0.6077963696418514\n",
            "  (1, 314)\t0.12412397117587953\n",
            "  (1, 304)\t0.195895158349055\n",
            "  (1, 297)\t0.179300406910585\n",
            "  (1, 291)\t0.24744316457161303\n",
            "  (1, 254)\t0.26883752016703377\n",
            "  (1, 220)\t0.2058256280255748\n",
            "  (1, 204)\t0.2989911707941711\n",
            "  (1, 174)\t0.21728951394447577\n",
            "  (1, 145)\t0.43457902788895153\n",
            "  (1, 129)\t0.2989911707941711\n",
            "  (1, 91)\t0.2989911707941711\n",
            "  (1, 84)\t0.26883752016703377\n",
            "  (1, 51)\t0.2989911707941711\n",
            "  (1, 45)\t0.26883752016703377\n",
            "  (2, 314)\t0.12968049259292613\n",
            "  (2, 302)\t0.31237577997390453\n",
            "  (2, 297)\t0.3746539023848952\n",
            "  (2, 291)\t0.2585201808031976\n",
            "  (2, 272)\t0.31237577997390453\n",
            "  (2, 240)\t0.31237577997390453\n",
            "  (2, 209)\t0.31237577997390453\n",
            "  :\t:\n",
            "  (38, 208)\t0.2924375349945174\n",
            "  (38, 172)\t0.1738160221150615\n",
            "  (38, 160)\t0.1738160221150615\n",
            "  (38, 36)\t0.2363643653556932\n",
            "  (38, 26)\t0.2924375349945174\n",
            "  (39, 323)\t0.21999909011270793\n",
            "  (39, 296)\t0.21999909011270793\n",
            "  (39, 286)\t0.21999909011270793\n",
            "  (39, 280)\t0.21999909011270793\n",
            "  (39, 278)\t0.21999909011270793\n",
            "  (39, 251)\t0.21999909011270793\n",
            "  (39, 242)\t0.21999909011270793\n",
            "  (39, 238)\t0.19781189413656503\n",
            "  (39, 224)\t0.15988263209192122\n",
            "  (39, 198)\t0.21999909011270793\n",
            "  (39, 190)\t0.19781189413656503\n",
            "  (39, 180)\t0.21999909011270793\n",
            "  (39, 154)\t0.21999909011270793\n",
            "  (39, 140)\t0.21999909011270793\n",
            "  (39, 118)\t0.21999909011270793\n",
            "  (39, 105)\t0.21999909011270793\n",
            "  (39, 81)\t0.21999909011270793\n",
            "  (39, 59)\t0.19781189413656503\n",
            "  (39, 37)\t0.39562378827313005\n",
            "  (39, 11)\t0.15144745166630824\n"
          ]
        }
      ],
      "source": [
        "vect = TfidfVectorizer().fit(nltk_tokens)\n",
        "X = vect.transform(nltk_tokens)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYLwYAh9Q-2y"
      },
      "source": [
        "TF,IDF word level"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zu8rjMbdOfNS",
        "outputId": "abdee959-8476-4ee4-92e9-2ff616b4cfd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (0, 98)\t1.0\n",
            "  (1, 11)\t1.0\n",
            "  (2, 20)\t1.0\n",
            "  (3, 10)\t1.0\n",
            "  (5, 51)\t1.0\n",
            "  (6, 84)\t1.0\n",
            "  (7, 145)\t1.0\n",
            "  (8, 45)\t1.0\n",
            "  (9, 314)\t1.0\n",
            "  (10, 254)\t1.0\n",
            "  (11, 297)\t1.0\n",
            "  (12, 304)\t1.0\n",
            "  (13, 91)\t1.0\n",
            "  (14, 145)\t1.0\n",
            "  (15, 129)\t1.0\n",
            "  (16, 204)\t1.0\n",
            "  (17, 220)\t1.0\n",
            "  (18, 291)\t1.0\n",
            "  (19, 174)\t1.0\n",
            "  (21, 297)\t1.0\n",
            "  (22, 172)\t1.0\n",
            "  (24, 302)\t1.0\n",
            "  (25, 36)\t1.0\n",
            "  (26, 63)\t1.0\n",
            "  (27, 240)\t1.0\n",
            "  :\t:\n",
            "  (708, 299)\t1.0\n",
            "  (709, 281)\t1.0\n",
            "  (710, 172)\t1.0\n",
            "  (711, 214)\t1.0\n",
            "  (713, 251)\t1.0\n",
            "  (714, 296)\t1.0\n",
            "  (715, 278)\t1.0\n",
            "  (716, 11)\t1.0\n",
            "  (717, 118)\t1.0\n",
            "  (718, 198)\t1.0\n",
            "  (719, 238)\t1.0\n",
            "  (721, 286)\t1.0\n",
            "  (722, 37)\t1.0\n",
            "  (723, 154)\t1.0\n",
            "  (725, 140)\t1.0\n",
            "  (727, 224)\t1.0\n",
            "  (728, 81)\t1.0\n",
            "  (729, 323)\t1.0\n",
            "  (731, 59)\t1.0\n",
            "  (732, 190)\t1.0\n",
            "  (734, 280)\t1.0\n",
            "  (735, 242)\t1.0\n",
            "  (736, 180)\t1.0\n",
            "  (737, 37)\t1.0\n",
            "  (738, 105)\t1.0\n"
          ]
        }
      ],
      "source": [
        "vect = TfidfVectorizer().fit(nltk_tokens_word)\n",
        "X = vect.transform(nltk_tokens_word)\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOxoYRc9sd2P"
      },
      "source": [
        "TD IDF character lvl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3L6I5ONRDfJ",
        "outputId": "30efa1e5-7d13-40a0-841e-11427b3009fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4173"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from math import log\n",
        "from collections import Counter\n",
        "char_counts = Counter(text)\n",
        "N = len(text)\n",
        "N"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiuV9qbxs3TH",
        "outputId": "377798d1-43d5-4f30-ca5e-c9411cd2d3df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'\\ufeff': 0.00016610284700693633, 'D': 0.000498308541020809, 'i': 0.04302063737479651, 's': 0.04235622598676876, 'c': 0.01993234164083236, 'u': 0.013288227760554907, 'o': 0.043186740221803445, 'n': 0.038535860505609226, ' ': 0.11743471283390398, 'a': 0.04219012313976183, 'b': 0.006478011033270516, 't': 0.050495265490108646, 'A': 0.003488159787145663, 'I': 0.0038203654811595354, 'd': 0.017773004629742187, '.': 0.006311908186263581, 'B': 0.0006644113880277453, 'r': 0.03189174662533178, 'h': 0.026908661215123683, 'v': 0.007806833809326007, 'e': 0.06577672741474679, 'g': 0.009633965126402307, 'z': 0.0011627199290485542, 'f': 0.010298376514430052, 'm': 0.012291610678513289, 'l': 0.019600135946818486, 'y': 0.007972936656332945, 'T': 0.0023254398580971085, ',': 0.008471245197353754, 'p': 0.011128890749464734, 'w': 0.004816982563201153, 'P': 0.00033220569401387265, 'W': 0.0008305142350346817, '(': 0.0014949256230624268, '1': 0.0018271313170762995, '9': 0.001993234164083236, '6': 0.000498308541020809, ')': 0.0014949256230624268, '\\n': 0.0011627199290485542, 'F': 0.00016610284700693633, 'x': 0.0014949256230624268, 'q': 0.0006644113880277453, '2': 0.0013288227760554906, ';': 0.00033220569401387265, 'R': 0.00033220569401387265, '3': 0.00016610284700693633, 'k': 0.002159337011090172, 'j': 0.000498308541020809, 'C': 0.0016610284700693634, 'L': 0.00016610284700693633, '0': 0.000996617082041618, '8': 0.00033220569401387265, 'V': 0.00016610284700693633, 'O': 0.00016610284700693633, '!': 0.00016610284700693633, 'Q': 0.00016610284700693633, '—': 0.00033220569401387265, 'G': 0.00033220569401387265, '?': 0.00016610284700693633, 'S': 0.00033220569401387265, 'Z': 0.00016610284700693633, 'K': 0.00016610284700693633, '“': 0.00016610284700693633, '”': 0.00016610284700693633, '’': 0.00016610284700693633, '-': 0.00033220569401387265, 'M': 0.00016610284700693633, 'H': 0.00016610284700693633, '7': 0.00016610284700693633}\n"
          ]
        }
      ],
      "source": [
        "tf_idf = {}\n",
        "for char, tf in char_counts.items():\n",
        "    tf = tf/N\n",
        "\n",
        "    n_contining_term = 1\n",
        "\n",
        "    idf = log(1+(1/n_contining_term))\n",
        "\n",
        "    tf_idf[char] = tf*idf\n",
        "\n",
        "print(tf_idf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jxvfLBY0wfv",
        "outputId": "78465432-d740-484b-fb2c-c7d8630eac89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iAWcARz20hsQ"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "word_tokens = [nltk.word_tokenize(text.lower())]\n",
        "word2vec_model = Word2Vec(word_tokens, vector_size=100, window=5, min_count=1, sg=0)\n",
        "word2vec_features = word2vec_model.wv['AI']  # Example for the word 'Royce'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y8sdH6Tr05p3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}